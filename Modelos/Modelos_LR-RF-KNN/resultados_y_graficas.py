# -*- coding: utf-8 -*-
"""Resultados y graficas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SS_SxQpz1bXMl0wvoAxrKu4EPvxMP8Wu

# Librerias
"""

import numpy as np
import matplotlib.pyplot as plt
import math
import seaborn as sn
import pandas as pd
from math import e
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn import linear_model
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import  accuracy_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import  roc_curve
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestClassifier
from sklearn import preprocessing
from sklearn.model_selection import StratifiedShuffleSplit
from mlxtend.plotting import plot_confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score
from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, roc_curve
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
from sklearn.pipeline import Pipeline
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.externals import joblib



"""#Resultados y graficas

## G1
"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG1.csv'
TrainG1 = pd.read_csv(csv_path, sep=',')

TrainG1.Respiracion = TrainG1.Respiracion.replace(["No valido"], -1)
TrainG1.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)

y = (TrainG1["SepsisLabel"])
X = (TrainG1.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train1, X_test1, y_train1, y_test1 = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train1.shape, y_train1.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test1.shape, y_test1.shape))

C_LR1 = joblib.load("/content/ModeloG1_RL (1).pkl")
C_RF1 = joblib.load("/content/ModeloG1_RF (1).pkl")
C_KNN1 = joblib.load("/content/ModeloG1_KNN (1).pkl")

# Accuracy promedio para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_score1 = C_LR1.score(X_test1, y_test1)
RF_score1 = C_RF1.score(X_test1, y_test1)
KNN_score1 = C_KNN1.score(X_test1, y_test1)

print(" Regresión Logistica SCORE :", LR_score1 )
print(" Random Forest SCORE :", RF_score1 )
print(" KNN SCORE :", KNN_score1 )

# Se realiza la predicción para los tres modelos LR_score1 - RF_score1 - KNN_score1
y_pred_LR1 = C_LR1.predict(X_test1)
y_pred_RF1 = C_RF1.predict(X_test1)
y_pred_KNN1 = C_KNN1.predict(X_test1)

# Se realiza f1_score para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_f1Score1 = f1_score(y_test1, y_pred_LR1)
RF_f1Score1 = f1_score(y_test1, y_pred_RF1)
KNN_f1Score1 = f1_score(y_test1, y_pred_KNN1)

print(" Regresión Logistica F1_SCORE :", LR_f1Score1 )
print(" Random Forest F1_SCORE :", RF_f1Score1 )
print(" KNN F1_SCORE :", KNN_f1Score1 )

#Matriz de Confusión para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_cm1= confusion_matrix(y_test1, y_pred_LR1)
RF_cm1= confusion_matrix(y_test1, y_pred_RF1)
KNN_cm1= confusion_matrix(y_test1, y_pred_KNN1)

print(" Regresión Logistica F1_SCORE : \n", LR_cm1 )
print(" Random Forest F1_SCORE : \n", RF_cm1 )
print(" KNN F1_SCORE : \n", KNN_cm1 )

plot_confusion_matrix(conf_mat=LR_cm1, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=RF_cm1, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=KNN_cm1, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_y_test_pred1 = C_LR1.predict(X_test1)
LR_y_test_prob1 = C_LR1.predict_proba(X_test1)

RF_y_test_pred1 = C_RF1.predict(X_test1)
RF_y_test_prob1 = C_RF1.predict_proba(X_test1)

KNN_y_test_pred1 = C_KNN1.predict(X_test1)
KNN_y_test_prob1 = C_KNN1.predict_proba(X_test1)

#Crear metricas para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_auc1 = roc_auc_score(y_test1, LR_y_test_prob1[:,1])
RF_auc1 = roc_auc_score(y_test1, RF_y_test_prob1[:,1])
KNN_auc1 = roc_auc_score(y_test1, KNN_y_test_prob1[:,1])

print("- LR AUC : ", round(LR_auc1,2))
print("- RF AUC: ", round(RF_auc1,2))
print("- KNN AUC: ", round(KNN_auc1,2))

LR_fpr1, LR_tpr1, LR_thrs1 = roc_curve(y_test1, LR_y_test_prob1[:,1])
RF_fpr1, RF_tpr1, RF_thrs1 = roc_curve(y_test1, RF_y_test_prob1[:,1])
KNN_fpr1, KNN_tpr1, KNN_thrs1 = roc_curve(y_test1, KNN_y_test_prob1[:,1])


fig = plt.figure(figsize=(10,10))
fig.tight_layout()
plt.plot(LR_fpr1,LR_tpr1, label='LR', color= 'green')
plt.plot(RF_fpr1,RF_tpr1, label='RF', color= 'orange')
plt.plot(KNN_fpr1,KNN_tpr1, label='KNN', color='blue')

plt.plot([0,1], [0,1], "r--")
plt.title("ROC")


plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Positivos")
plt.legend()
plt.show()

"""## G2"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG2.csv'
TrainG2 = pd.read_csv(csv_path, sep=',')

TrainG2.Respiracion = TrainG2.Respiracion.replace(["No valido"], -1)
TrainG2.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)

y = (TrainG2["SepsisLabel"])
X = (TrainG2.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train2, X_test2, y_train2, y_test2 = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train2.shape, y_train2.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test2.shape, y_test2.shape))

C_LR2 = joblib.load("/content/ModeloG2_RL (1).pkl")
C_RF2 = joblib.load("/content/ModeloG2_RF (1).pkl")
C_KNN2 = joblib.load("/content/ModeloG2_KNN (1).pkl")

# Accuracy promedio para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_score2 = C_LR2.score(X_test2, y_test2)
RF_score2 = C_RF2.score(X_test2, y_test2)
KNN_score2 = C_KNN2.score(X_test2, y_test2)

print(" Regresión Logistica SCORE :", LR_score2 )
print(" Random Forest SCORE :", RF_score2 )
print(" KNN SCORE :", KNN_score2 )

# Se realiza la predicción para los tres modelos LR_score1 - RF_score1 - KNN_score1
y_pred_LR2 = C_LR2.predict(X_test2)
y_pred_RF2 = C_RF2.predict(X_test2)
y_pred_KNN2 = C_KNN2.predict(X_test2)

# Se realiza f1_score para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_f1Score2 = f1_score(y_test2, y_pred_LR2)
RF_f1Score2 = f1_score(y_test2, y_pred_RF2)
KNN_f1Score2 = f1_score(y_test2, y_pred_KNN2)

print(" Regresión Logistica F1_SCORE :", LR_f1Score2 )
print(" Random Forest F1_SCORE :", RF_f1Score2 )
print(" KNN F1_SCORE :", KNN_f1Score2 )

#Matriz de Confusión para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_cm2= confusion_matrix(y_test2, y_pred_LR2)
RF_cm2= confusion_matrix(y_test2, y_pred_RF2)
KNN_cm2= confusion_matrix(y_test2, y_pred_KNN2)

print(" Regresión Logistica F1_SCORE : \n", LR_cm2 )
print(" Random Forest F1_SCORE : \n", RF_cm2 )
print(" KNN F1_SCORE : \n", KNN_cm2 )

plot_confusion_matrix(conf_mat=LR_cm2, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=RF_cm2, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=KNN_cm2, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_y_test_pred2 = C_LR2.predict(X_test2)
LR_y_test_prob2 = C_LR2.predict_proba(X_test2)

RF_y_test_pred2 = C_RF2.predict(X_test2)
RF_y_test_prob2 = C_RF2.predict_proba(X_test2)

KNN_y_test_pred2 = C_KNN2.predict(X_test2)
KNN_y_test_prob2 = C_KNN2.predict_proba(X_test2)

#Crear metricas para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_auc2 = roc_auc_score(y_test2, LR_y_test_prob2[:,1])
RF_auc2 = roc_auc_score(y_test2, RF_y_test_prob2[:,1])
KNN_auc2 = roc_auc_score(y_test2, KNN_y_test_prob2[:,1])

print("- LR AUC : ", round(LR_auc2,2))
print("- RF AUC: ", round(RF_auc2,2))
print("- KNN AUC: ", round(KNN_auc2,2))

LR_fpr2, LR_tpr2, LR_thrs2 = roc_curve(y_test2, LR_y_test_prob2[:,1])
RF_fpr2, RF_tpr2, RF_thrs2 = roc_curve(y_test2, RF_y_test_prob2[:,1])
KNN_fpr2, KNN_tpr2, KNN_thrs2 = roc_curve(y_test2, KNN_y_test_prob2[:,1])


fig = plt.figure(figsize=(10,10))
fig.tight_layout()
plt.plot(LR_fpr2,LR_tpr2, label='LR', color= 'green')
plt.plot(RF_fpr2,RF_tpr2, label='RF', color= 'orange')
plt.plot(KNN_fpr2,KNN_tpr2, label='KNN', color='blue')

plt.plot([0,1], [0,1], "r--")
plt.title("ROC")


plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Positivos")
plt.legend()
plt.show()

"""## G3"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG3.csv'
TrainG3 = pd.read_csv(csv_path, sep=',')

TrainG3.Respiracion = TrainG3.Respiracion.replace(["No valido"], -1)
TrainG3.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)

y = (TrainG3["SepsisLabel"])
X = (TrainG3.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train3, X_test3, y_train3, y_test3 = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train3.shape, y_train3.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test3.shape, y_test3.shape))

C_LR3 = joblib.load("/content/ModeloG3_RL (1).pkl")
C_RF3 = joblib.load("/content/ModeloG3_RF (1).pkl")
C_KNN3 = joblib.load("/content/ModeloG3_KNN (1).pkl")

# Accuracy promedio para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_score3 = C_LR3.score(X_test3, y_test3)
RF_score3 = C_RF3.score(X_test3, y_test3)
KNN_score3 = C_KNN3.score(X_test3, y_test3)

print(" Regresión Logistica SCORE :", LR_score3 )
print(" Random Forest SCORE :", RF_score3 )
print(" KNN SCORE :", KNN_score3 )

# Se realiza la predicción para los tres modelos LR_score1 - RF_score1 - KNN_score1
y_pred_LR3 = C_LR3.predict(X_test3)
y_pred_RF3 = C_RF3.predict(X_test3)
y_pred_KNN3 = C_KNN3.predict(X_test3)

# Se realiza f1_score para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_f1Score3 = f1_score(y_test3, y_pred_LR3)
RF_f1Score3 = f1_score(y_test3, y_pred_RF3)
KNN_f1Score3 = f1_score(y_test3, y_pred_KNN3)

print(" Regresión Logistica F1_SCORE :", LR_f1Score3 )
print(" Random Forest F1_SCORE :", RF_f1Score3 )
print(" KNN F1_SCORE :", KNN_f1Score3 )

#Matriz de Confusión para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_cm3= confusion_matrix(y_test3, y_pred_LR3)
RF_cm3= confusion_matrix(y_test3, y_pred_RF3)
KNN_cm3= confusion_matrix(y_test3, y_pred_KNN3)

print(" Regresión Logistica F1_SCORE : \n", LR_cm3 )
print(" Random Forest F1_SCORE : \n", RF_cm3 )
print(" KNN F1_SCORE : \n", KNN_cm3 )

plot_confusion_matrix(conf_mat=LR_cm3, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=RF_cm3, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=KNN_cm3, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_y_test_pred3 = C_LR3.predict(X_test3)
LR_y_test_prob3 = C_LR3.predict_proba(X_test3)

RF_y_test_pred3 = C_RF3.predict(X_test3)
RF_y_test_prob3 = C_RF3.predict_proba(X_test3)

KNN_y_test_pred3 = C_KNN3.predict(X_test3)
KNN_y_test_prob3 = C_KNN3.predict_proba(X_test3)

#Crear metricas para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_auc3 = roc_auc_score(y_test3, LR_y_test_prob3[:,1])
RF_auc3 = roc_auc_score(y_test3, RF_y_test_prob3[:,1])
KNN_auc3 = roc_auc_score(y_test3, KNN_y_test_prob3[:,1])

print("- LR AUC : ", round(LR_auc3,2))
print("- RF AUC: ", round(RF_auc3,2))
print("- KNN AUC: ", round(KNN_auc3,2))

LR_fpr3, LR_tpr3, LR_thrs3 = roc_curve(y_test3, LR_y_test_prob3[:,1])
RF_fpr3, RF_tpr3, RF_thrs3 = roc_curve(y_test3, RF_y_test_prob3[:,1])
KNN_fpr3, KNN_tpr3, KNN_thrs3 = roc_curve(y_test3, KNN_y_test_prob3[:,1])


fig = plt.figure(figsize=(10,10))
fig.tight_layout()
plt.plot(LR_fpr3,LR_tpr3, label='LR', color= 'green')
plt.plot(RF_fpr3,RF_tpr3, label='RF', color= 'orange')
plt.plot(KNN_fpr3,KNN_tpr3, label='KNN', color='blue')

plt.plot([0,1], [0,1], "r--")
plt.title("ROC")


plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Positivos")
plt.legend()
plt.show()

"""## G4"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG4.csv'
TrainG4 = pd.read_csv(csv_path, sep=',')

TrainG4.Respiracion = TrainG4.Respiracion.replace(["No valido"], -1)
TrainG4.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)

y = (TrainG4["SepsisLabel"])
X = (TrainG4.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train4, X_test4, y_train4, y_test4 = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train4.shape, y_train4.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test4.shape, y_test4.shape))

C_LR4 = joblib.load("/content/ModeloG4_RL (1).pkl")
C_RF4 = joblib.load("/content/ModeloG4_RF (1).pkl")
C_KNN4 = joblib.load("/content/ModeloG4_KNN (1).pkl")

# Accuracy promedio para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_score4 = C_LR4.score(X_test4, y_test4)
RF_score4 = C_RF4.score(X_test4, y_test4)
KNN_score4 = C_KNN4.score(X_test4, y_test4)

print(" Regresión Logistica SCORE :", LR_score4 )
print(" Random Forest SCORE :", RF_score4 )
print(" KNN SCORE :", KNN_score4 )

# Se realiza la predicción para los tres modelos LR_score1 - RF_score1 - KNN_score1
y_pred_LR4 = C_LR4.predict(X_test4)
y_pred_RF4 = C_RF4.predict(X_test4)
y_pred_KNN4 = C_KNN4.predict(X_test4)

# Se realiza f1_score para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_f1Score4 = f1_score(y_test4, y_pred_LR4)
RF_f1Score4 = f1_score(y_test4, y_pred_RF4)
KNN_f1Score4 = f1_score(y_test4, y_pred_KNN4)

print(" Regresión Logistica F1_SCORE :", LR_f1Score4 )
print(" Random Forest F1_SCORE :", RF_f1Score4 )
print(" KNN F1_SCORE :", KNN_f1Score4 )

#Matriz de Confusión para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_cm4= confusion_matrix(y_test4, y_pred_LR4)
RF_cm4= confusion_matrix(y_test4, y_pred_RF4)
KNN_cm4= confusion_matrix(y_test4, y_pred_KNN4)

print(" Regresión Logistica F1_SCORE : \n", LR_cm4 )
print(" Random Forest F1_SCORE : \n", RF_cm4 )
print(" KNN F1_SCORE : \n", KNN_cm4 )

plot_confusion_matrix(conf_mat=LR_cm4, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=RF_cm4, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=KNN_cm4, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_y_test_pred4 = C_LR4.predict(X_test4)
LR_y_test_prob4 = C_LR4.predict_proba(X_test4)

RF_y_test_pred4 = C_RF4.predict(X_test4)
RF_y_test_prob4 = C_RF4.predict_proba(X_test4)

KNN_y_test_pred4 = C_KNN4.predict(X_test4)
KNN_y_test_prob4 = C_KNN4.predict_proba(X_test4)

#Crear metricas para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_auc4 = roc_auc_score(y_test4, LR_y_test_prob4[:,1])
RF_auc4 = roc_auc_score(y_test4, RF_y_test_prob4[:,1])
KNN_auc4 = roc_auc_score(y_test4, KNN_y_test_prob4[:,1])

print("- LR AUC : ", round(LR_auc4,2))
print("- RF AUC: ", round(RF_auc4,2))
print("- KNN AUC: ", round(KNN_auc4,2))

LR_fpr4, LR_tpr4, LR_thrs4 = roc_curve(y_test4, LR_y_test_prob4[:,1])
RF_fpr4, RF_tpr4, RF_thrs4 = roc_curve(y_test4, RF_y_test_prob4[:,1])
KNN_fpr4, KNN_tpr4, KNN_thrs4 = roc_curve(y_test4, KNN_y_test_prob4[:,1])


fig = plt.figure(figsize=(10,10))
fig.tight_layout()
plt.plot(LR_fpr4,LR_tpr4, label='LR', color= 'green')
plt.plot(RF_fpr4,RF_tpr4, label='RF', color= 'orange')
plt.plot(KNN_fpr4,KNN_tpr4, label='KNN', color='blue')

plt.plot([0,1], [0,1], "r--")
plt.title("ROC")


plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Positivos")
plt.legend()
plt.show()

"""## G4 Test"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TestG4.csv'
TestG4 = pd.read_csv(csv_path, sep=',')

TestG4.Respiracion = TestG4.Respiracion.replace(["No valido"], -1)
TestG4.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)

y = (TestG4["SepsisLabel"])
X = (TestG4.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

C_LR4 = joblib.load("/content/ModeloG4_RL (1).pkl")
C_RF4 = joblib.load("/content/ModeloG4_RF (1).pkl")
C_KNN4 = joblib.load("/content/ModeloG4_KNN (1).pkl")

# Accuracy promedio para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_score4 = C_LR4.score(X, y)
RF_score4 = C_RF4.score(X, y)
KNN_score4 = C_KNN4.score(X, y)

print(" Regresión Logistica SCORE :", LR_score4 )
print(" Random Forest SCORE :", RF_score4 )
print(" KNN SCORE :", KNN_score4 )

# Se realiza la predicción para los tres modelos LR_score1 - RF_score1 - KNN_score1
y_pred_LR4 = C_LR4.predict(X)
y_pred_RF4 = C_RF4.predict(X)
y_pred_KNN4 = C_KNN4.predict(X)

# Se realiza f1_score para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_f1Score4 = f1_score(y, y_pred_LR4)
RF_f1Score4 = f1_score(y, y_pred_RF4)
KNN_f1Score4 = f1_score(y, y_pred_KNN4)

print(" Regresión Logistica F1_SCORE :", LR_f1Score4 )
print(" Random Forest F1_SCORE :", RF_f1Score4 )
print(" KNN F1_SCORE :", KNN_f1Score4 )

#Matriz de Confusión para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_cm4= confusion_matrix(y, y_pred_LR4)
RF_cm4= confusion_matrix(y, y_pred_RF4)
KNN_cm4= confusion_matrix(y, y_pred_KNN4)

print(" Regresión Logistica F1_SCORE : \n", LR_cm4 )
print(" Random Forest F1_SCORE : \n", RF_cm4 )
print(" KNN F1_SCORE : \n", KNN_cm4 )

plot_confusion_matrix(conf_mat=LR_cm4, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=RF_cm4, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=KNN_cm4, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_y_test_pred4 = C_LR4.predict(X)
LR_y_test_prob4 = C_LR4.predict_proba(X)

RF_y_test_pred4 = C_RF4.predict(X)
RF_y_test_prob4 = C_RF4.predict_proba(X)

KNN_y_test_pred4 = C_KNN4.predict(X)
KNN_y_test_prob4 = C_KNN4.predict_proba(X)

#Crear metricas para los tres modelos LR_score1 - RF_score1 - KNN_score1

LR_auc4 = roc_auc_score(y, LR_y_test_prob4[:,1])
RF_auc4 = roc_auc_score(y, RF_y_test_prob4[:,1])
KNN_auc4 = roc_auc_score(y, KNN_y_test_prob4[:,1])

print("- LR AUC : ", round(LR_auc4,2))
print("- RF AUC: ", round(RF_auc4,2))
print("- KNN AUC: ", round(KNN_auc4,2))

LR_fpr4, LR_tpr4, LR_thrs4 = roc_curve(y, LR_y_test_prob4[:,1])
RF_fpr4, RF_tpr4, RF_thrs4 = roc_curve(y, RF_y_test_prob4[:,1])
KNN_fpr4, KNN_tpr4, KNN_thrs4 = roc_curve(y, KNN_y_test_prob4[:,1])


fig = plt.figure(figsize=(10,10))
fig.tight_layout()
plt.plot(LR_fpr4,LR_tpr4, label='LR', color= 'green')
plt.plot(RF_fpr4,RF_tpr4, label='RF', color= 'orange')
plt.plot(KNN_fpr4,KNN_tpr4, label='KNN', color='blue')

plt.plot([0,1], [0,1], "r--")
plt.title("ROC")


plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Positivos")
plt.legend()
plt.show()