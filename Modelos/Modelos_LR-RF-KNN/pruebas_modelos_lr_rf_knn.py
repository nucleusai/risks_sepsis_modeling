# -*- coding: utf-8 -*-
"""PRUEBAS MODELOS LR-RF-KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FOwVUsnpTmiTUnxis1i16ooMrScf5fXl

# Librerias
"""

import numpy as np
import matplotlib.pyplot as plt
import math
import seaborn as sn
import pandas as pd
from math import e
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn import linear_model
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import  accuracy_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import  roc_curve
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestClassifier
from sklearn import preprocessing
from sklearn.model_selection import StratifiedShuffleSplit
from mlxtend.plotting import plot_confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score
from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, roc_curve
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
from sklearn.pipeline import Pipeline
from sklearn.model_selection import RepeatedStratifiedKFold
import joblib

"""# GridSearchCV Comparando los modelos"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG1.csv'
TrainG1 = pd.read_csv(csv_path, sep=',')

TrainG1.Respiracion = TrainG1.Respiracion.replace(["No valido"], -1)
TrainG1.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar
X = (TrainG1[["Bilirubin_total","Creatinine","MAP","Platelets","Respiracion","HR"]])
y = (TrainG1["SepsisLabel"])

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

#Crear tuberia de uso
pipe = Pipeline([("classifier", KNeighborsClassifier())])

search_space = [
                {"classifier" : [LogisticRegression()],
                 "classifier__penalty" : ["11","12"],
                 "classifier__max_iter" : [500,1000]},
                
                {"classifier" : [RandomForestClassifier()],
                 "classifier__criterion" : ['gini','entropy'],
                 "classifier__max_depth" : [range(1,10)],
                 "classifier__min_samples_leaf" : [range(1,5)],
                 "classifier__min_samples_split" : [range(1,10)]},
                
                {"classifier" : [KNeighborsClassifier()],
                 "classifier__n_neighbors" : [4,5,6,7,8,9,10],
                 "classifier__leaf_size" : [1,3,5,7],
                 "classifier__algorithm" : ['auto', 'kd_tree']}]

#Crear el clasificador con GridSearchCV
clf = GridSearchCV(pipe, search_space, cv=5, verbose=0, n_jobs=4)

#Buscar el mejor modelo de todos los que hay en el pipline
mejor_modelo = clf.fit(X_train, y_train)
print(mejor_modelo.best_estimator_.get_params()["classifier"])

{"classifier" : [KNeighborsClassifier()],
                 "classifier__n_neighbors" : [4,5,6,7,8,9,10],
                 "classifier__leaf_size" : [1,3,5,7],
                 "classifier__algorithm" : ['auto', 'kd_tree']}

#Predecir resultados en el conjunto de evaluación
y_test_pred = clf.predict(X_test)
y_test_prob = clf.predict_proba(X_test)

#Crear metricas

auc = roc_auc_score(y_test, y_test_prob[:,1])
print("- Precisión: ", round(precision_score(y_test, y_test_pred),2))
print("- Recall: ", round(recall_score(y_test, y_test_pred),2))
print("- F-Score: ", round(f1_score(y_test, y_test_pred),2))
print("- AUC: ", round(auc,2))

#Curva AUC

fpr, tpr, thrs = roc_curve(y_test, y_test_prob[:,1])
plt.plot(fpr,tpr)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

#Matriz de Confusión
cm= confusion_matrix(y_test, y_test_pred)
cm

matriz = confusion_matrix(y_test,y_test_pred)

plot_confusion_matrix(conf_mat=matriz, figsize=(6,6), show_normed=False)
plt.tight_layout()

"""# PRUEBAS EN CONJUNTO TRAIN

## G1
"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG1.csv'
TrainG1 = pd.read_csv(csv_path, sep=',')

TrainG1.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG1.drop(["a"], axis=1, inplace=True)

TrainG1.Respiracion = TrainG1.Respiracion.replace(["No valido"], -1)
TrainG1.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG1["SepsisLabel"])
X = (TrainG1.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

C_LR1 = joblib.load("/content/ModeloG1_RL (1).pkl")
C_RF1 = joblib.load("/content/ModeloG1_RF (1).pkl")
C_KNN1 = joblib.load("/content/ModeloG1_KNN (1).pkl")

# Accuracy promedio

LR_score1 = C_LR1.score(X_test, y_test)
RF_score1 = C_RF1.score(X_test, y_test)
KNN_score1 = C_KNN1.score(X_test, y_test)

print(" Regresión Logistica SCORE :", LR_score1 )
print(" Random Forest SCORE :", RF_score1 )
print(" KNN SCORE :", KNN_score1 )

# Se realiza la predicción

y_predLR1 = C_LR1.predict(X_test)
y_predRF1 = C_RF1.predict(X_test)
y_predKNN1 = C_KNN1.predict(X_test)

# F1 Score

LR_F11 = f1_score(y_test, y_predLR1)
RF_F11 = f1_score(y_test, y_predRF1)
KNN_F11 = f1_score(y_test, y_predKNN1)

print(" Regresión Logistica F1SCORE :", LR_F11 )
print(" Random Forest F1SCORE :", RF_F11 )
print(" KNN F1SCORE :", KNN_F11 )

#Matriz de Confusión

LR_cm1= confusion_matrix(y_test, y_predLR1)
RF_cm1= confusion_matrix(y_test, y_predRF1)
KNN_cm1= confusion_matrix(y_test, y_predKNN1)

print(" Regresión Logistica F1SCORE :", LR_cm1 )
print(" Random Forest F1SCORE :", RF_cm1 )
print(" KNN F1SCORE :", KNN_cm1 )

plot_confusion_matrix(conf_mat=LR_cm1, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=RF_cm1, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=KNN_cm1, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación

y_test_predLR1 = C_LR1.predict(X_test)
y_test_probLR1 = C_LR1.predict_proba(X_test)

y_test_predRF1 = C_RF1.predict(X_test)
y_test_probRF1 = C_RF1.predict_proba(X_test)

y_test_predKNN1 = C_KNN1.predict(X_test)
y_test_probKNN1 = C_KNN1.predict_proba(X_test)

#Crear metricas
LR_auc1 = roc_auc_score(y_test, y_test_probLR1[:,1])
RF_auc1 = roc_auc_score(y_test, y_test_probRF1[:,1])
KNN_auc1 = roc_auc_score(y_test, y_test_probKNN1[:,1])

print("- LR AUC: ", round(LR_auc1,2))
print("- RF AUC: ", round(RF_auc1,2))
print("- KNN AUC: ", round(KNN_auc1,2))

LRfpr1, LRtpr1, thrs1 = roc_curve(y_test, y_test_probLR1[:,1])
RFfpr1, RFtpr1, thrs1 = roc_curve(y_test, y_test_probRF1[:,1])
KNNfpr1, KNNtpr1, thrs1 = roc_curve(y_test, y_test_probKNN1[:,1])

plt.plot(LRfpr1,LRtpr1, label='REGRESION LOGISTICA', color= 'green')
plt.plot(RFfpr1,RFtpr1,  label='RANDOM FOREST', color= 'ORANGE')
plt.plot(KNNfpr1,KNNtpr1, label='KNN', color= 'cyan')
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.legend()
plt.show()

"""## G2"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG2.csv'
TrainG2 = pd.read_csv(csv_path, sep=',')

TrainG2.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG2.drop(["a"], axis=1, inplace=True)

TrainG2.Respiracion = TrainG2.Respiracion.replace(["No valido"], -1)
TrainG2.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG2["SepsisLabel"])
X = (TrainG2.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

C_LR2 = joblib.load("/content/ModeloG2_RL (1).pkl")
C_RF2 = joblib.load("/content/ModeloG2_RF (1).pkl")
C_KNN2 = joblib.load("/content/ModeloG2_KNN (1).pkl")

# Accuracy promedio

LR_score2 = C_LR2.score(X_test, y_test)
RF_score2 = C_RF2.score(X_test, y_test)
KNN_score2 = C_KNN2.score(X_test, y_test)

print(" Regresión Logistica SCORE :", LR_score2 )
print(" Random Forest SCORE :", RF_score2 )
print(" KNN SCORE :", KNN_score2 )

# Se realiza la predicción

y_predLR2 = C_LR2.predict(X_test)
y_predRF2 = C_RF2.predict(X_test)
y_predKNN2 = C_KNN2.predict(X_test)

# F1 Score

LR_F12 = f1_score(y_test, y_predLR2)
RF_F12 = f1_score(y_test, y_predRF2)
KNN_F12 = f1_score(y_test, y_predKNN2)

print(" Regresión Logistica F1SCORE :", LR_F12 )
print(" Random Forest F1SCORE :", RF_F12 )
print(" KNN F1SCORE :", KNN_F12 )

#Matriz de Confusión

LR_cm2= confusion_matrix(y_test, y_predLR2)
RF_cm2= confusion_matrix(y_test, y_predRF2)
KNN_cm2= confusion_matrix(y_test, y_predKNN2)

print(" Regresión Logistica F1SCORE :", LR_cm2 )
print(" Random Forest F1SCORE :", RF_cm2 )
print(" KNN F1SCORE :", KNN_cm2 )

plot_confusion_matrix(conf_mat=LR_cm2, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=RF_cm2, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=KNN_cm2, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación

y_test_predLR2 = C_LR2.predict(X_test)
y_test_probLR2 = C_LR2.predict_proba(X_test)

y_test_predRF2 = C_RF2.predict(X_test)
y_test_probRF2 = C_RF2.predict_proba(X_test)

y_test_predKNN2 = C_KNN2.predict(X_test)
y_test_probKNN2 = C_KNN2.predict_proba(X_test)

#Crear metricas
LR_auc2 = roc_auc_score(y_test, y_test_probLR2[:,1])
RF_auc2 = roc_auc_score(y_test, y_test_probRF2[:,1])
KNN_auc2 = roc_auc_score(y_test, y_test_probKNN2[:,1])

print("- LR AUC: ", round(LR_auc2,2))
print("- RF AUC: ", round(RF_auc2,2))
print("- KNN AUC: ", round(KNN_auc2,2))

LRfpr2, LRtpr2, thrs2 = roc_curve(y_test, y_test_probLR2[:,1])
RFfpr2, RFtpr2, thrs2 = roc_curve(y_test, y_test_probRF2[:,1])
KNNfpr2, KNNtpr2, thrs2 = roc_curve(y_test, y_test_probKNN2[:,1])

plt.plot(LRfpr2,LRtpr2, label='REGRESION LOGISTICA', color= 'green')
plt.plot(RFfpr2,RFtpr2,  label='RANDOM FOREST', color= 'ORANGE')
plt.plot(KNNfpr2,KNNtpr2, label='KNN', color= 'cyan')
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.legend()
plt.show()

"""## G3"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG3.csv'
TrainG3 = pd.read_csv(csv_path, sep=',')

TrainG3.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG3.drop(["a"], axis=1, inplace=True)

TrainG3.Respiracion = TrainG3.Respiracion.replace(["No valido"], -1)
TrainG3.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG3["SepsisLabel"])
X = (TrainG3.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

C_LR3 = joblib.load("/content/ModeloG3_RL (1).pkl")
C_RF3 = joblib.load("/content/ModeloG3_RF (1).pkl")
C_KNN3 = joblib.load("/content/ModeloG3_KNN (1).pkl")

# Accuracy promedio

LR_score3 = C_LR3.score(X_test, y_test)
RF_score3 = C_RF3.score(X_test, y_test)
KNN_score3 = C_KNN3.score(X_test, y_test)

print(" Regresión Logistica SCORE :", LR_score3 )
print(" Random Forest SCORE :", RF_score3 )
print(" KNN SCORE :", KNN_score3 )

# Se realiza la predicción

y_predLR3 = C_LR3.predict(X_test)
y_predRF3 = C_RF3.predict(X_test)
y_predKNN3 = C_KNN3.predict(X_test)

# F1 Score

LR_F13 = f1_score(y_test, y_predLR3)
RF_F13 = f1_score(y_test, y_predRF3)
KNN_F13 = f1_score(y_test, y_predKNN3)

print(" Regresión Logistica F1SCORE :", LR_F13 )
print(" Random Forest F1SCORE :", RF_F13 )
print(" KNN F1SCORE :", KNN_F13 )

#Matriz de Confusión

LR_cm3= confusion_matrix(y_test, y_predLR3)
RF_cm3= confusion_matrix(y_test, y_predRF3)
KNN_cm3= confusion_matrix(y_test, y_predKNN3)

print(" Regresión Logistica F1SCORE :", LR_cm3 )
print(" Random Forest F1SCORE :", RF_cm3 )
print(" KNN F1SCORE :", KNN_cm3 )

plot_confusion_matrix(conf_mat=LR_cm3, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=RF_cm3, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=KNN_cm3, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación

y_test_predLR3 = C_LR3.predict(X_test)
y_test_probLR3 = C_LR3.predict_proba(X_test)

y_test_predRF3 = C_RF3.predict(X_test)
y_test_probRF3 = C_RF3.predict_proba(X_test)

y_test_predKNN3 = C_KNN3.predict(X_test)
y_test_probKNN3 = C_KNN3.predict_proba(X_test)

#Crear metricas
LR_auc3 = roc_auc_score(y_test, y_test_probLR3[:,1])
RF_auc3 = roc_auc_score(y_test, y_test_probRF3[:,1])
KNN_auc3 = roc_auc_score(y_test, y_test_probKNN3[:,1])

print("- LR AUC: ", round(LR_auc3,2))
print("- RF AUC: ", round(RF_auc3,2))
print("- KNN AUC: ", round(KNN_auc3,2))

LRfpr3, LRtpr3, thrs3 = roc_curve(y_test, y_test_probLR3[:,1])
RFfpr3, RFtpr3, thrs3 = roc_curve(y_test, y_test_probRF3[:,1])
KNNfpr3, KNNtpr3, thrs3 = roc_curve(y_test, y_test_probKNN3[:,1])

plt.plot(LRfpr3,LRtpr3, label='REGRESION LOGISTICA', color= 'green')
plt.plot(RFfpr3,RFtpr3,  label='RANDOM FOREST', color= 'ORANGE')
plt.plot(KNNfpr3,KNNtpr3, label='KNN', color= 'cyan')
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.legend()
plt.show()

"""## G4"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG4.csv'
TrainG4 = pd.read_csv(csv_path, sep=',')

TrainG4.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG4.drop(["a"], axis=1, inplace=True)

TrainG4.Respiracion = TrainG4.Respiracion.replace(["No valido"], -1)
TrainG4.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG4["SepsisLabel"])
X = (TrainG4.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

C_LR4 = joblib.load("/content/ModeloG4_RL (1).pkl")
C_RF4 = joblib.load("/content/ModeloG4_RF (1).pkl")
C_KNN4 = joblib.load("/content/ModeloG4_KNN (1).pkl")

# Accuracy promedio

LR_score4 = C_LR4.score(X_test, y_test)
RF_score4 = C_RF4.score(X_test, y_test)
KNN_score4 = C_KNN4.score(X_test, y_test)

print(" Regresión Logistica SCORE :", LR_score4 )
print(" Random Forest SCORE :", RF_score4 )
print(" KNN SCORE :", KNN_score4 )

# Se realiza la predicción

y_predLR4 = C_LR4.predict(X_test)
y_predRF4 = C_RF4.predict(X_test)
y_predKNN4 = C_KNN4.predict(X_test)

# F1 Score

LR_F14 = f1_score(y_test, y_predLR4)
RF_F14 = f1_score(y_test, y_predRF4)
KNN_F14 = f1_score(y_test, y_predKNN4)

print(" Regresión Logistica F1SCORE :", LR_F14 )
print(" Random Forest F1SCORE :", RF_F14 )
print(" KNN F1SCORE :", KNN_F14 )

#Matriz de Confusión

LR_cm4= confusion_matrix(y_test, y_predLR4)
RF_cm4= confusion_matrix(y_test, y_predRF4)
KNN_cm4= confusion_matrix(y_test, y_predKNN4)

print(" Regresión Logistica F1SCORE :", LR_cm4 )
print(" Random Forest F1SCORE :", RF_cm4 )
print(" KNN F1SCORE :", KNN_cm4 )

plot_confusion_matrix(conf_mat=LR_cm4, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=RF_cm4, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=KNN_cm4, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación

y_test_predLR4 = C_LR4.predict(X_test)
y_test_probLR4 = C_LR4.predict_proba(X_test)

y_test_predRF4 = C_RF4.predict(X_test)
y_test_probRF4 = C_RF4.predict_proba(X_test)

y_test_predKNN4 = C_KNN4.predict(X_test)
y_test_probKNN4 = C_KNN4.predict_proba(X_test)

#Crear metricas
LR_auc4 = roc_auc_score(y_test, y_test_probLR4[:,1])
RF_auc4 = roc_auc_score(y_test, y_test_probRF4[:,1])
KNN_auc4 = roc_auc_score(y_test, y_test_probKNN4[:,1])

print("- LR AUC: ", round(LR_auc4,2))
print("- RF AUC: ", round(RF_auc4,2))
print("- KNN AUC: ", round(KNN_auc4,2))

LRfpr4, LRtpr4, thrs4 = roc_curve(y_test, y_test_probLR4[:,1])
RFfpr4, RFtpr4, thrs4 = roc_curve(y_test, y_test_probRF4[:,1])
KNNfpr4, KNNtpr4, thrs4 = roc_curve(y_test, y_test_probKNN4[:,1])

plt.plot(LRfpr4,LRtpr4, label='REGRESION LOGISTICA', color= 'green')
plt.plot(RFfpr4,RFtpr4,  label='RANDOM FOREST', color= 'ORANGE')
plt.plot(KNNfpr4,KNNtpr4, label='KNN', color= 'cyan')
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.legend()
plt.show()

"""# PRUEBAS EN CONJUNTO TEST

## G1
"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TestG1.csv'
TestG1 = pd.read_csv(csv_path, sep=',')

TestG1.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TestG1.drop(["a"], axis=1, inplace=True)

TestG1.Respiracion = TestG1.Respiracion.replace(["No valido"], -1)
TestG1.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TestG1["SepsisLabel"])
X = (TestG1.drop(['SepsisLabel','Paciente'], axis=1))

C_LR1 = joblib.load("/content/ModeloG1_RL (1).pkl")
C_RF1 = joblib.load("/content/ModeloG1_RF (1).pkl")
C_KNN1 = joblib.load("/content/ModeloG1_KNN (1).pkl")

# Accuracy promedio

LR_score1 = C_LR1.score(X, y)
RF_score1 = C_RF1.score(X, y)
KNN_score1 = C_KNN1.score(X, y)

print(" Regresión Logistica SCORE :", LR_score1 )
print(" Random Forest SCORE :", RF_score1 )
print(" KNN SCORE :", KNN_score1 )

# Se realiza la predicción

y_predLR1 = C_LR1.predict(X)
y_predRF1 = C_RF1.predict(X)
y_predKNN1 = C_KNN1.predict(X)

# F1 Score

LR_F11 = f1_score(y, y_predLR1)
RF_F11 = f1_score(y, y_predRF1)
KNN_F11 = f1_score(y, y_predKNN1)

print(" Regresión Logistica F1SCORE :", LR_F11 )
print(" Random Forest F1SCORE :", RF_F11 )
print(" KNN F1SCORE :", KNN_F11 )

#Matriz de Confusión

LR_cm1= confusion_matrix(y, y_predLR1)
RF_cm1= confusion_matrix(y, y_predRF1)
KNN_cm1= confusion_matrix(y, y_predKNN1)

print(" Regresión Logistica F1SCORE :", LR_cm1 )
print(" Random Forest F1SCORE :", RF_cm1 )
print(" KNN F1SCORE :", KNN_cm1 )

plot_confusion_matrix(conf_mat=LR_cm1, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=RF_cm1, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=KNN_cm1, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación

y_test_predLR1 = C_LR1.predict(X)
y_test_probLR1 = C_LR1.predict_proba(X)

y_test_predRF1 = C_RF1.predict(X)
y_test_probRF1 = C_RF1.predict_proba(X)

y_test_predKNN1 = C_KNN1.predict(X)
y_test_probKNN1 = C_KNN1.predict_proba(X)

#Crear metricas
LR_auc1 = roc_auc_score(y, y_test_probLR1[:,1])
RF_auc1 = roc_auc_score(y, y_test_probRF1[:,1])
KNN_auc1 = roc_auc_score(y, y_test_probKNN1[:,1])

print("- LR AUC: ", round(LR_auc1,2))
print("- RF AUC: ", round(RF_auc1,2))
print("- KNN AUC: ", round(KNN_auc1,2))

LRfpr1, LRtpr1, thrs1 = roc_curve(y, y_test_probLR1[:,1])
RFfpr1, RFtpr1, thrs1 = roc_curve(y, y_test_probRF1[:,1])
KNNfpr1, KNNtpr1, thrs1 = roc_curve(y, y_test_probKNN1[:,1])

plt.plot(LRfpr1,LRtpr1, label='REGRESION LOGISTICA', color= 'green')
plt.plot(RFfpr1,RFtpr1,  label='RANDOM FOREST', color= 'ORANGE')
plt.plot(KNNfpr1,KNNtpr1, label='KNN', color= 'cyan')
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.legend()
plt.show()

"""## G2"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TestG2.csv'
TestG2 = pd.read_csv(csv_path, sep=',')

TestG2.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TestG2.drop(["a"], axis=1, inplace=True)

TestG2.Respiracion = TestG2.Respiracion.replace(["No valido"], -1)
TestG2.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TestG2["SepsisLabel"])
X = (TestG2.drop(['SepsisLabel','Paciente'], axis=1))

C_LR2 = joblib.load("/content/ModeloG2_RL (1).pkl")
C_RF2 = joblib.load("/content/ModeloG2_RF (1).pkl")
C_KNN2 = joblib.load("/content/ModeloG2_KNN (1).pkl")

# Accuracy promedio

LR_score2 = C_LR2.score(X, y)
RF_score2 = C_RF2.score(X, y)
KNN_score2 = C_KNN2.score(X, y)

print(" Regresión Logistica SCORE :", LR_score2 )
print(" Random Forest SCORE :", RF_score2 )
print(" KNN SCORE :", KNN_score2 )

# Se realiza la predicción

y_predLR2 = C_LR2.predict(X)
y_predRF2 = C_RF2.predict(X)
y_predKNN2 = C_KNN2.predict(X)

# F1 Score

LR_F12 = f1_score(y, y_predLR2)
RF_F12 = f1_score(y, y_predRF2)
KNN_F12 = f1_score(y, y_predKNN2)

print(" Regresión Logistica F1SCORE :", LR_F12 )
print(" Random Forest F1SCORE :", RF_F12 )
print(" KNN F1SCORE :", KNN_F12 )

#Matriz de Confusión

LR_cm2= confusion_matrix(y, y_predLR2)
RF_cm2= confusion_matrix(y, y_predRF2)
KNN_cm2= confusion_matrix(y, y_predKNN2)

print(" Regresión Logistica F1SCORE :", LR_cm2 )
print(" Random Forest F1SCORE :", RF_cm2 )
print(" KNN F1SCORE :", KNN_cm2 )

plot_confusion_matrix(conf_mat=LR_cm2, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=RF_cm2, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=KNN_cm2, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación

y_test_predLR2 = C_LR2.predict(X)
y_test_probLR2 = C_LR2.predict_proba(X)

y_test_predRF2 = C_RF2.predict(X)
y_test_probRF2 = C_RF2.predict_proba(X)

y_test_predKNN2 = C_KNN2.predict(X)
y_test_probKNN2 = C_KNN2.predict_proba(X)

#Crear metricas
LR_auc2 = roc_auc_score(y, y_test_probLR2[:,1])
RF_auc2 = roc_auc_score(y, y_test_probRF2[:,1])
KNN_auc2 = roc_auc_score(y, y_test_probKNN2[:,1])

print("- LR AUC: ", round(LR_auc2,2))
print("- RF AUC: ", round(RF_auc2,2))
print("- KNN AUC: ", round(KNN_auc2,2))

LRfpr2, LRtpr2, thrs2 = roc_curve(y, y_test_probLR2[:,1])
RFfpr2, RFtpr2, thrs2 = roc_curve(y, y_test_probRF2[:,1])
KNNfpr2, KNNtpr2, thrs2 = roc_curve(y, y_test_probKNN2[:,1])

plt.plot(LRfpr2,LRtpr2, label='REGRESION LOGISTICA', color= 'green')
plt.plot(RFfpr2,RFtpr2,  label='RANDOM FOREST', color= 'ORANGE')
plt.plot(KNNfpr2,KNNtpr2, label='KNN', color= 'cyan')
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.legend()
plt.show()

"""## G3"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TestG3.csv'
TestG3 = pd.read_csv(csv_path, sep=',')

TestG3.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TestG3.drop(["a"], axis=1, inplace=True)

TestG3.Respiracion = TestG3.Respiracion.replace(["No valido"], -1)
TestG3.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TestG3["SepsisLabel"])
X = (TestG3.drop(['SepsisLabel','Paciente'], axis=1))

C_LR3 = joblib.load("/content/ModeloG3_RL (1).pkl")
C_RF3 = joblib.load("/content/ModeloG3_RF (1).pkl")
C_KNN3 = joblib.load("/content/ModeloG3_KNN (1).pkl")

# Accuracy promedio

LR_score3 = C_LR3.score(X, y)
RF_score3 = C_RF3.score(X, y)
KNN_score3 = C_KNN3.score(X, y)

print(" Regresión Logistica SCORE :", LR_score3 )
print(" Random Forest SCORE :", RF_score3 )
print(" KNN SCORE :", KNN_score3 )

# Se realiza la predicción

y_predLR3 = C_LR3.predict(X)
y_predRF3 = C_RF3.predict(X)
y_predKNN3 = C_KNN3.predict(X)

# F1 Score

LR_F13 = f1_score(y, y_predLR3)
RF_F13 = f1_score(y, y_predRF3)
KNN_F13 = f1_score(y, y_predKNN3)

print(" Regresión Logistica F1SCORE :", LR_F13 )
print(" Random Forest F1SCORE :", RF_F13 )
print(" KNN F1SCORE :", KNN_F13 )

#Matriz de Confusión

LR_cm3= confusion_matrix(y, y_predLR3)
RF_cm3= confusion_matrix(y, y_predRF3)
KNN_cm3= confusion_matrix(y, y_predKNN3)

print(" Regresión Logistica F1SCORE :", LR_cm3 )
print(" Random Forest F1SCORE :", RF_cm3 )
print(" KNN F1SCORE :", KNN_cm3 )

plot_confusion_matrix(conf_mat=LR_cm3, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=RF_cm3, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=KNN_cm3, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación

y_test_predLR3 = C_LR3.predict(X)
y_test_probLR3 = C_LR3.predict_proba(X)

y_test_predRF3 = C_RF3.predict(X)
y_test_probRF3 = C_RF3.predict_proba(X)

y_test_predKNN3 = C_KNN3.predict(X)
y_test_probKNN3 = C_KNN3.predict_proba(X)

#Crear metricas
LR_auc3 = roc_auc_score(y, y_test_probLR3[:,1])
RF_auc3 = roc_auc_score(y, y_test_probRF3[:,1])
KNN_auc3 = roc_auc_score(y, y_test_probKNN3[:,1])

print("- LR AUC: ", round(LR_auc3,2))
print("- RF AUC: ", round(RF_auc3,2))
print("- KNN AUC: ", round(KNN_auc3,2))

LRfpr3, LRtpr3, thrs3 = roc_curve(y, y_test_probLR3[:,1])
RFfpr3, RFtpr3, thrs3 = roc_curve(y, y_test_probRF3[:,1])
KNNfpr3, KNNtpr3, thrs3 = roc_curve(y, y_test_probKNN3[:,1])

plt.plot(LRfpr3,LRtpr3, label='REGRESION LOGISTICA', color= 'green')
plt.plot(RFfpr3,RFtpr3,  label='RANDOM FOREST', color= 'ORANGE')
plt.plot(KNNfpr3,KNNtpr3, label='KNN', color= 'cyan')
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.legend()
plt.show()

"""## G4"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TestG4.csv'
TestG4 = pd.read_csv(csv_path, sep=',')

TestG4.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TestG4.drop(["a"], axis=1, inplace=True)

TestG4.Respiracion = TestG4.Respiracion.replace(["No valido"], -1)
TestG4.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TestG4["SepsisLabel"])
X = (TestG4.drop(['SepsisLabel','Paciente'], axis=1))

C_LR4 = joblib.load("/content/ModeloG4_RL (1).pkl")
C_RF4 = joblib.load("/content/ModeloG4_RF (1).pkl")
C_KNN4 = joblib.load("/content/ModeloG4_KNN (1).pkl")

# Accuracy promedio

LR_score4 = C_LR4.score(X, y)
RF_score4 = C_RF4.score(X, y)
KNN_score4 = C_KNN4.score(X, y)

print(" Regresión Logistica SCORE :", LR_score4 )
print(" Random Forest SCORE :", RF_score4 )
print(" KNN SCORE :", KNN_score4 )

# Se realiza la predicción

y_predLR4 = C_LR4.predict(X)
y_predRF4 = C_RF4.predict(X)
y_predKNN4 = C_KNN4.predict(X)

# F1 Score

LR_F14 = f1_score(y, y_predLR4)
RF_F14 = f1_score(y, y_predRF4)
KNN_F14 = f1_score(y, y_predKNN4)

print(" Regresión Logistica F1SCORE :", LR_F14 )
print(" Random Forest F1SCORE :", RF_F14 )
print(" KNN F1SCORE :", KNN_F14 )

#Matriz de Confusión

LR_cm4= confusion_matrix(y, y_predLR4)
RF_cm4= confusion_matrix(y, y_predRF4)
KNN_cm4= confusion_matrix(y, y_predKNN4)

print(" Regresión Logistica F1SCORE :", LR_cm4 )
print(" Random Forest F1SCORE :", RF_cm4 )
print(" KNN F1SCORE :", KNN_cm4 )

plot_confusion_matrix(conf_mat=LR_cm4, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=RF_cm4, figsize=(4,4), show_normed= False)
plot_confusion_matrix(conf_mat=KNN_cm4, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación

y_test_predLR4 = C_LR4.predict(X)
y_test_probLR4 = C_LR4.predict_proba(X)

y_test_predRF4 = C_RF4.predict(X)
y_test_probRF4 = C_RF4.predict_proba(X)

y_test_predKNN4 = C_KNN4.predict(X)
y_test_probKNN4 = C_KNN4.predict_proba(X)

#Crear metricas
LR_auc4 = roc_auc_score(y, y_test_probLR4[:,1])
RF_auc4 = roc_auc_score(y, y_test_probRF4[:,1])
KNN_auc4 = roc_auc_score(y, y_test_probKNN4[:,1])

print("- LR AUC: ", round(LR_auc4,2))
print("- RF AUC: ", round(RF_auc4,2))
print("- KNN AUC: ", round(KNN_auc4,2))

LRfpr4, LRtpr4, thrs4 = roc_curve(y, y_test_probLR4[:,1])
RFfpr4, RFtpr4, thrs4 = roc_curve(y, y_test_probRF4[:,1])
KNNfpr4, KNNtpr4, thrs4 = roc_curve(y, y_test_probKNN4[:,1])

plt.plot(LRfpr4,LRtpr4, label='REGRESION LOGISTICA', color= 'green')
plt.plot(RFfpr4,RFtpr4,  label='RANDOM FOREST', color= 'ORANGE')
plt.plot(KNNfpr4,KNNtpr4, label='KNN', color= 'cyan')
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.legend()
plt.show()