# -*- coding: utf-8 -*-
"""GridSearchCV_PorClasificador.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15U1vJCb0gbaCydlNeCwNpHk2z47lS3VO

# Librerias
"""

import numpy as np
import matplotlib.pyplot as plt
import math
import seaborn as sn
import pandas as pd
from math import e
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn import linear_model
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import  accuracy_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import  roc_curve
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestClassifier
from sklearn import preprocessing
from sklearn.model_selection import StratifiedShuffleSplit
from mlxtend.plotting import plot_confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score
from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, roc_curve
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
from sklearn.pipeline import Pipeline
from sklearn.model_selection import RepeatedStratifiedKFold
import joblib

"""# Grupo 1

## GridSearchCV_Regresión Logistica G1
"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG1.csv'
TrainG1 = pd.read_csv(csv_path, sep=',')

TrainG1.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG1.drop(["a"], axis=1, inplace=True)

TrainG1.Respiracion = TrainG1.Respiracion.replace(["No valido"], -1)
TrainG1.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)

y = (TrainG1["SepsisLabel"])
X = (TrainG1.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

# define model
model = LogisticRegression()

# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)

# define search space
space = dict()
space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']
space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']
space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]

# define search
search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)

# execute search
result = search.fit(X_train, y_train)

# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

# Score de predicción
LRscore1 = search.score(X_test, y_test)
LRscore1

joblib.dump(search, 'ModeloG1_RL.pkl')

# Se realiza la predicción
y_pred = search.predict(X_test)
y_pred

LRpuntaje1 = f1_score(y_test, y_pred)
print(LRpuntaje1)

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred)
cm

plot_confusion_matrix(conf_mat=cm, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación
y_test_pred = search.predict(X_test)
y_test_prob = search.predict_proba(X_test)

#Crear metricas
LRauc1 = roc_auc_score(y_test, y_test_prob[:,1])
print("- AUC: ", round(LRauc1,2))

fpr, tpr, thrs = roc_curve(y_test, y_test_prob[:,1])
plt.plot(fpr,tpr)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

"""## GridSearchCV_Random Forest G1"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG1.csv'
TrainG1 = pd.read_csv(csv_path, sep=',')

TrainG1.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG1.drop(["a"], axis=1, inplace=True)

TrainG1.Respiracion = TrainG1.Respiracion.replace(["No valido"], -1)
TrainG1.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG1["SepsisLabel"])
X = (TrainG1.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

# Creaamos el modelo de Bosques Aleatorios (y configuramos el número de estimadores (árboles de decisión))
BA_model = RandomForestClassifier(n_estimators = 19, random_state = 2016,min_samples_leaf = 8,)

# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)

# define search space
space = dict()
space['criterion'] = ['gini', 'entropy']
space['max_depth'] = [1,2,3,4,5,6,7,8,9,10]
space['min_samples_leaf'] = [1,2,3,4,5]
space['min_samples_split'] = [1,2,3,4,5,6,7,8,9,10]

# define search
search = GridSearchCV(BA_model, space, scoring='accuracy', n_jobs=-1, cv=cv)

# execute search
result = search.fit(X_train, y_train)

# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

# Accuracy promedio
RFscore1 = search.score(X_test, y_test)
RFscore1

joblib.dump(search, 'ModeloG1_RF.pkl')

# Se realiza la predicción
y_pred = search.predict(X_test)
y_pred

RFpuntaje1 = f1_score(y_test, y_pred)
print(RFpuntaje1)

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred)
cm

# Predicción del modelo usando los datos de prueba
y_pred = search.predict(X_test)
matriz = confusion_matrix(y_test,y_pred)

plot_confusion_matrix(conf_mat=matriz, figsize=(6,6), show_normed=False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación
y_test_pred = search.predict(X_test)
y_test_prob = search.predict_proba(X_test)

#Crear metricas
RFauc1 = roc_auc_score(y_test, y_test_prob[:,1])
print("- AUC: ", round(RFauc1,2))

#Curva AUC

fpr, tpr, thrs = roc_curve(y_test, y_test_prob[:,1])
plt.plot(fpr,tpr)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

"""## GridSearchCV_KNeighbors G1


"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG1.csv'
TrainG1 = pd.read_csv(csv_path, sep=',')

TrainG1.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG1.drop(["a"], axis=1, inplace=True)

TrainG1.Respiracion = TrainG1.Respiracion.replace(["No valido"], -1)
TrainG1.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG1["SepsisLabel"])
X = (TrainG1.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

# define model
model = KNeighborsClassifier()

# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)

# define search space
space = dict()
space['algorithm'] = ['auto', 'kd_tree']
space['leaf_size'] = [1,3,5,7]
space['n_neighbors'] = [4,5,6,7,8,9,10]

# define search
search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)

# execute search
result = search.fit(X_train, y_train)

# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

# Accuracy promedio
KNNscore1 = search.score(X_test, y_test)
KNNscore1

joblib.dump(search, 'ModeloG1_KNN.pkl')

# Se realiza la predicción
y_pred = search.predict(X_test)
y_pred

KNNpuntaje1 = f1_score(y_test, y_pred)
print(KNNpuntaje1)

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred)
cm

# Predicción del modelo usando los datos de prueba
y_pred = search.predict(X_test)
matriz = confusion_matrix(y_test,y_pred)

plot_confusion_matrix(conf_mat=matriz, figsize=(6,6), show_normed=False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación
y_test_pred = search.predict(X_test)
y_test_prob = search.predict_proba(X_test)

#Crear metricas
KNNauc1 = roc_auc_score(y_test, y_test_prob[:,1])
print("- AUC: ", round(KNNauc1,2))

#Curva AUC

fpr, tpr, thrs = roc_curve(y_test, y_test_prob[:,1])
plt.plot(fpr,tpr)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

"""# Grupo 2

## GridSearchCV_Regresión Logistica G2
"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG2.csv'
TrainG2 = pd.read_csv(csv_path, sep=',')

TrainG2.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG2.drop(["a"], axis=1, inplace=True)

TrainG2.Respiracion = TrainG2.Respiracion.replace(["No valido"], -1)
TrainG2.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG2["SepsisLabel"])
X = (TrainG2.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

# define model
model = LogisticRegression()

# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)

# define search space
space = dict()
space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']
space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']
space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]

# define search
search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)

# execute search
result = search.fit(X_train, y_train)

# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

# Score de predicción
LRscore2 = search.score(X_test, y_test)
LRscore2

joblib.dump(search, 'ModeloG2_RL.pkl')

# Se realiza la predicción
y_pred = search.predict(X_test)
y_pred

LRpuntaje2 = f1_score(y_test, y_pred)
print(LRpuntaje2)

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred)
cm

plot_confusion_matrix(conf_mat=cm, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación
y_test_pred = search.predict(X_test)
y_test_prob = search.predict_proba(X_test)

#Crear metricas
LRauc2 = roc_auc_score(y_test, y_test_prob[:,1])
print("- AUC: ", round(LRauc2,2))

fpr, tpr, thrs = roc_curve(y_test, y_test_prob[:,1])
plt.plot(fpr,tpr)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

"""## GridSearchCV_Random Forest G2"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG2.csv'
TrainG2 = pd.read_csv(csv_path, sep=',')

TrainG2.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG2.drop(["a"], axis=1, inplace=True)

TrainG2.Respiracion = TrainG2.Respiracion.replace(["No valido"], -1)
TrainG2.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG2["SepsisLabel"])
X = (TrainG2.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

# Creaamos el modelo de Bosques Aleatorios (y configuramos el número de estimadores (árboles de decisión))
BA_model = RandomForestClassifier(n_estimators = 19, random_state = 2016,min_samples_leaf = 8,)

# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)

# define search space
space = dict()
space['criterion'] = ['gini', 'entropy']
space['max_depth'] = [1,2,3,4,5,6,7,8,9,10]
space['min_samples_leaf'] = [1,2,3,4,5]
space['min_samples_split'] = [1,2,3,4,5,6,7,8,9,10]

# define search
search = GridSearchCV(BA_model, space, scoring='accuracy', n_jobs=-1, cv=cv)

# execute search
result = search.fit(X_train, y_train)

# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

# Accuracy promedio
RFscore2 = search.score(X_test, y_test)
RFscore2

joblib.dump(search, 'ModeloG2_RF.pkl')

# Se realiza la predicción
y_pred = search.predict(X_test)
y_pred

RFpuntaje2 = f1_score(y_test, y_pred)
print(RFpuntaje2)

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred)
cm

# Predicción del modelo usando los datos de prueba
y_pred = search.predict(X_test)
matriz = confusion_matrix(y_test,y_pred)

plot_confusion_matrix(conf_mat=matriz, figsize=(6,6), show_normed=False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación
y_test_pred = search.predict(X_test)
y_test_prob = search.predict_proba(X_test)

#Crear metricas
RFauc2 = roc_auc_score(y_test, y_test_prob[:,1])
print("- AUC: ", round(RFauc2,2))

#Curva AUC

fpr, tpr, thrs = roc_curve(y_test, y_test_prob[:,1])
plt.plot(fpr,tpr)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

"""## GridSearchCV_KNeighbors G2


"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG2.csv'
TrainG2 = pd.read_csv(csv_path, sep=',')

TrainG2.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG2.drop(["a"], axis=1, inplace=True)

TrainG2.Respiracion = TrainG2.Respiracion.replace(["No valido"], -1)
TrainG2.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG2["SepsisLabel"])
X = (TrainG2.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

# define model
model = KNeighborsClassifier()

# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)

# define search space
space = dict()
space['algorithm'] = ['auto', 'kd_tree']
space['leaf_size'] = [1,3,5,7]
space['n_neighbors'] = [4,5,6,7,8,9,10]

# define search
search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)

# execute search
result = search.fit(X_train, y_train)

# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

# Accuracy promedio
KNNscore2 = search.score(X_test, y_test)
KNNscore2

joblib.dump(search, 'ModeloG2_KNN.pkl')

# Se realiza la predicción
y_pred = search.predict(X_test)
y_pred

KNNpuntaje2 = f1_score(y_test, y_pred)
print(KNNpuntaje2)

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred)
cm

# Predicción del modelo usando los datos de prueba
y_pred = search.predict(X_test)
matriz = confusion_matrix(y_test,y_pred)

plot_confusion_matrix(conf_mat=matriz, figsize=(6,6), show_normed=False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación
y_test_pred = search.predict(X_test)
y_test_prob = search.predict_proba(X_test)

#Crear metricas
KNNauc2 = roc_auc_score(y_test, y_test_prob[:,1])
print("- AUC: ", round(KNNauc2,2))

#Curva AUC

fpr, tpr, thrs = roc_curve(y_test, y_test_prob[:,1])
plt.plot(fpr,tpr)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

"""# Grupo 3

## GridSearchCV_Regresión Logistica G3
"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG3.csv'
TrainG3 = pd.read_csv(csv_path, sep=',')

TrainG3.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG3.drop(["a"], axis=1, inplace=True)

TrainG3.Respiracion = TrainG3.Respiracion.replace(["No valido"], -1)
TrainG3.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG3["SepsisLabel"])
X = (TrainG3.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

# define model
model = LogisticRegression()

# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)

# define search space
space = dict()
space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']
space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']
space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]

# define search
search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)

# execute search
result = search.fit(X_train, y_train)

# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

# Score de predicción
LRscore3 = search.score(X_test, y_test)
LRscore3

joblib.dump(search, 'ModeloG3_RL.pkl')

# Se realiza la predicción
y_pred = search.predict(X_test)
y_pred

LRpuntaje3 = f1_score(y_test, y_pred)
print(LRpuntaje3)

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred)
cm

plot_confusion_matrix(conf_mat=cm, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación
y_test_pred = search.predict(X_test)
y_test_prob = search.predict_proba(X_test)

#Crear metricas
LRauc3 = roc_auc_score(y_test, y_test_prob[:,1])
print("- AUC: ", round(LRauc3,2))

fpr, tpr, thrs = roc_curve(y_test, y_test_prob[:,1])
plt.plot(fpr,tpr)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

"""## GridSearchCV_Random Forest G3"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG3.csv'
TrainG3 = pd.read_csv(csv_path, sep=',')

TrainG3.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG3.drop(["a"], axis=1, inplace=True)

TrainG3.Respiracion = TrainG3.Respiracion.replace(["No valido"], -1)
TrainG3.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG3["SepsisLabel"])
X = (TrainG3.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

# Creaamos el modelo de Bosques Aleatorios (y configuramos el número de estimadores (árboles de decisión))
BA_model = RandomForestClassifier(n_estimators = 19, random_state = 2016,min_samples_leaf = 8,)

# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)

# define search space
space = dict()
space['criterion'] = ['gini', 'entropy']
space['max_depth'] = [1,2,3,4,5,6,7,8,9,10]
space['min_samples_leaf'] = [1,2,3,4,5]
space['min_samples_split'] = [1,2,3,4,5,6,7,8,9,10]

# define search
search = GridSearchCV(BA_model, space, scoring='accuracy', n_jobs=-1, cv=cv)

# execute search
result = search.fit(X_train, y_train)

# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

# Accuracy promedio
RFscore3 = search.score(X_test, y_test)
RFscore3

joblib.dump(search, 'ModeloG3_RF.pkl')

# Se realiza la predicción
y_pred = search.predict(X_test)
y_pred

RFpuntaje3 = f1_score(y_test, y_pred)
print(RFpuntaje3)

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred)
cm

# Predicción del modelo usando los datos de prueba
y_pred = search.predict(X_test)
matriz = confusion_matrix(y_test,y_pred)

plot_confusion_matrix(conf_mat=matriz, figsize=(6,6), show_normed=False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación
y_test_pred = search.predict(X_test)
y_test_prob = search.predict_proba(X_test)

#Crear metricas
RFauc3 = roc_auc_score(y_test, y_test_prob[:,1])
print("- AUC: ", round(RFauc3,2))

#Curva AUC

fpr, tpr, thrs = roc_curve(y_test, y_test_prob[:,1])
plt.plot(fpr,tpr)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

"""## GridSearchCV_KNeighbors G3



"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG3.csv'
TrainG3 = pd.read_csv(csv_path, sep=',')

TrainG3.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG3.drop(["a"], axis=1, inplace=True)

TrainG3.Respiracion = TrainG3.Respiracion.replace(["No valido"], -1)
TrainG3.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG3["SepsisLabel"])
X = (TrainG3.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

# define model
model = KNeighborsClassifier()

# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)

# define search space
space = dict()
space['algorithm'] = ['auto', 'kd_tree']
space['leaf_size'] = [1,3,5,7]
space['n_neighbors'] = [4,5,6,7,8,9,10]

# define search
search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)

# execute search
result = search.fit(X_train, y_train)

# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

# Accuracy promedio
KNNscore3 = search.score(X_test, y_test)
KNNscore3

joblib.dump(search, 'ModeloG3_KNN.pkl')

# Se realiza la predicción
y_pred = search.predict(X_test)
y_pred

KNNpuntaje3 = f1_score(y_test, y_pred)
print(KNNpuntaje3)

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred)
cm

# Predicción del modelo usando los datos de prueba
y_pred = search.predict(X_test)
matriz = confusion_matrix(y_test,y_pred)

plot_confusion_matrix(conf_mat=matriz, figsize=(6,6), show_normed=False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación
y_test_pred = search.predict(X_test)
y_test_prob = search.predict_proba(X_test)

#Crear metricas
KNNauc3 = roc_auc_score(y_test, y_test_prob[:,1])
print("- AUC: ", round(KNNauc3,2))

#Curva AUC

fpr, tpr, thrs = roc_curve(y_test, y_test_prob[:,1])
plt.plot(fpr,tpr)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

"""# Grupo 4

## GridSearchCV_Regresión Logistica G4
"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG4.csv'
TrainG4 = pd.read_csv(csv_path, sep=',')

TrainG4.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG4.drop(["a"], axis=1, inplace=True)

TrainG4.Respiracion = TrainG4.Respiracion.replace(["No valido"], -1)
TrainG4.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG4["SepsisLabel"])
X = (TrainG4.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

# define model
model = LogisticRegression()

# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)

# define search space
space = dict()
space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']
space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']
space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]

# define search
search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)

# execute search
result = search.fit(X_train, y_train)

# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

# Score de predicción
LRscore4 = search.score(X_test, y_test)
LRscore4

joblib.dump(search, 'ModeloG4_RL.pkl')

# Se realiza la predicción
y_pred = search.predict(X_test)
y_pred

LRpuntaje4 = f1_score(y_test, y_pred)
print(LRpuntaje3)

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred)
cm

plot_confusion_matrix(conf_mat=cm, figsize=(4,4), show_normed= False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación
y_test_pred = search.predict(X_test)
y_test_prob = search.predict_proba(X_test)

#Crear metricas
LRauc4 = roc_auc_score(y_test, y_test_prob[:,1])
print("- AUC: ", round(LRauc4,2))

fpr, tpr, thrs = roc_curve(y_test, y_test_prob[:,1])
plt.plot(fpr,tpr)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

"""## GridSearchCV_Random Forest G4"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG4.csv'
TrainG4 = pd.read_csv(csv_path, sep=',')

TrainG4.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG4.drop(["a"], axis=1, inplace=True)

TrainG4.Respiracion = TrainG4.Respiracion.replace(["No valido"], -1)
TrainG4.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG4["SepsisLabel"])
X = (TrainG4.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

# Creaamos el modelo de Bosques Aleatorios (y configuramos el número de estimadores (árboles de decisión))
BA_model = RandomForestClassifier(n_estimators = 19, random_state = 2016,min_samples_leaf = 8,)

# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)

# define search space
space = dict()
space['criterion'] = ['gini', 'entropy']
space['max_depth'] = [1,2,3,4,5,6,7,8,9,10]
space['min_samples_leaf'] = [1,2,3,4,5]
space['min_samples_split'] = [1,2,3,4,5,6,7,8,9,10]

# define search
search = GridSearchCV(BA_model, space, scoring='accuracy', n_jobs=-1, cv=cv)

# execute search
result = search.fit(X_train, y_train)

# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

# Accuracy promedio
RFscore4 = search.score(X_test, y_test)
RFscore4

joblib.dump(search, 'ModeloG4_RF.pkl')

# Se realiza la predicción
y_pred = search.predict(X_test)
y_pred

RFpuntaje4 = f1_score(y_test, y_pred)
print(RFpuntaje4)

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred)
cm

# Predicción del modelo usando los datos de prueba
y_pred = search.predict(X_test)
matriz = confusion_matrix(y_test,y_pred)

plot_confusion_matrix(conf_mat=matriz, figsize=(6,6), show_normed=False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación
y_test_pred = search.predict(X_test)
y_test_prob = search.predict_proba(X_test)

#Crear metricas
RFauc4 = roc_auc_score(y_test, y_test_prob[:,1])
print("- AUC: ", round(RFauc4,2))

#Curva AUC

fpr, tpr, thrs = roc_curve(y_test, y_test_prob[:,1])
plt.plot(fpr,tpr)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

"""## GridSearchCV_KNeighbors G4



"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG4.csv'
TrainG4 = pd.read_csv(csv_path, sep=',')

TrainG4.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG4.drop(["a"], axis=1, inplace=True)

TrainG4.Respiracion = TrainG4.Respiracion.replace(["No valido"], -1)
TrainG4.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG4["SepsisLabel"])
X = (TrainG4.drop(['SepsisLabel','Paciente'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

# define model
model = KNeighborsClassifier()

# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)

# define search space
space = dict()
space['algorithm'] = ['auto', 'kd_tree']
space['leaf_size'] = [1,3,5,7]
space['n_neighbors'] = [4,5,6,7,8,9,10]

# define search
search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)

# execute search
result = search.fit(X_train, y_train)

# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

# Accuracy promedio
KNNscore4 = search.score(X_test, y_test)
KNNscore4

joblib.dump(search, 'ModeloG4_KNN.pkl')

# Se realiza la predicción
y_pred = search.predict(X_test)
y_pred

KNNpuntaje4 = f1_score(y_test, y_pred)
print(KNNpuntaje4)

#Matriz de Confusión
cm= confusion_matrix(y_test4, y_pred4)
cm

# Predicción del modelo usando los datos de prueba
y_pred = search.predict(X_test)
matriz = confusion_matrix(y_test,y_pred)

plot_confusion_matrix(conf_mat=matriz, figsize=(6,6), show_normed=False)
plt.tight_layout()

#Predecir resultados en el conjunto de evaluación
y_test_pred = search.predict(X_test)
y_test_prob = search.predict_proba(X_test)

#Crear metricas
KNNauc4 = roc_auc_score(y_test, y_test_prob[:,1])
print("- AUC: ", round(KNNauc4,2))

#Curva AUC

fpr, tpr, thrs = roc_curve(y_test, y_test_prob[:,1])
plt.plot(fpr,tpr)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

"""# Tabla de resultados"""

datos = {'LR_Score': [ LRscore1, LRscore2, LRscore3, LRscore4],
         'RF_Score': [ RFscore1, RFscore2, RFscore3, RFscore4],
         'KNN_Score': [ KNNscore1, KNNscore2, KNNscore3, KNNscore4],
         'LR_F1': [ LRpuntaje1, LRpuntaje2, LRpuntaje3, LRpuntaje4],
         'RF_F1': [ RFpuntaje1, RFpuntaje2, RFpuntaje3, RFpuntaje4],
         'KNN_F1': [ KNNpuntaje1, KNNpuntaje2, KNNpuntaje3, KNNpuntaje4],
         'LR_AUC': [ LRauc1, LRauc2, LRauc3, LRauc4],
         'RF_AUC': [ RFauc1, RFauc2, RFauc3, RFauc4],
         'KNN_AUC': [ KNNauc1, KNNauc2, KNNauc3, KNNauc4]}

Resultados = pd.DataFrame(datos, index=['M1', 'M2', 'M3' , 'M4'])
Resultados.to_csv('ResultadosModelos.csv')
Resultados

from datetime import datetime
from sklearn import metrics
import seaborn as sns
import lightgbm as lgb

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG1.csv'
TrainG1 = pd.read_csv(csv_path, sep=',')

TrainG1.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG1.drop(["a"], axis=1, inplace=True)

TrainG1.Respiracion = TrainG1.Respiracion.replace(["No valido"], -1)
TrainG1.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)

y = (TrainG1["SepsisLabel"])
X = (TrainG1.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

d_train = lgb.Dataset(X_train, label=y_train)

lgbm_params = { 'learning_rate': 0.5, 'boosting_type':'gbdt',
                'objective':'binary',
                'metric':['auc', 'binary_logloss'],
                'num_leaves':100,
                'max_depth':10}

clf= lgb.train(lgbm_params, d_train, 50)

y_pred_lgbm = clf.predict(X_test)

for i in range (0, X_test.shape[0]):
   if y_pred_lgbm[i]>=.5:
      y_pred_lgbm[i]=1
   else:
      y_pred_lgbm[i]=0

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred_lgbm)
cm

plot_confusion_matrix(conf_mat=cm, figsize=(4,4), show_normed= False)
plt.tight_layout()



"""## LightGBM 1"""

import xgboost as xgb

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG1.csv'
TrainG1 = pd.read_csv(csv_path, sep=',')

TrainG1.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG1.drop(["a"], axis=1, inplace=True)

TrainG1.Respiracion = TrainG1.Respiracion.replace(["No valido"], -1)
TrainG1.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)

y = (TrainG1["SepsisLabel"])
X = (TrainG1.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

dtrain = xgb.DMatrix(X_train, label=y_train)

params = { 'learning_rate': .5,
           'objective':'binary:logistic',
           'eval_metric':'auc',
           'num_leaves':100,
           'max_depth':10}

xg=xgb.train(params, dtrain, 50)

dtest = xgb.DMatrix(X_test)
y_pred_xgb= xg.predict(dtest)

for i in range (0, X_test.shape[0]):
   if y_pred_xgb[i]>=.5:
      y_pred_xgb[i]=1
   else:
      y_pred_xgb[i]=0

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred_xgb)
cm

plot_confusion_matrix(conf_mat=cm, figsize=(4,4), show_normed= False)
plt.tight_layout()

metrics.accuracy_score(y_pred_xgb,y_test)

roc_auc= roc_auc_score(y_pred_xgb, y_test)
roc_auc

r_probs = [0 for _ in range(len(y_test))]

fpr, tpr, thrs = roc_curve(y_test, r_probs)

#Curva AUC

plt.plot(fpr,tpr)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

"""## LightGBM 2"""

import xgboost as xgb

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG2.csv'
TrainG2 = pd.read_csv(csv_path, sep=',')

TrainG2.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG2.drop(["a"], axis=1, inplace=True)

TrainG2.Respiracion = TrainG2.Respiracion.replace(["No valido"], -1)
TrainG2.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG2["SepsisLabel"])
X = (TrainG2.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

dtrain = xgb.DMatrix(X_train, label=y_train)

params = { 'learning_rate': .5,
           'objective':'binary:logistic',
           'eval_metric':'auc',
           'num_leaves':100,
           'max_depth':10}

xg=xgb.train(params, dtrain, 50)

dtest = xgb.DMatrix(X_test)
y_pred_xgb= xg.predict(dtest)

for i in range (0, X_test.shape[0]):
   if y_pred_xgb[i]>=.5:
      y_pred_xgb[i]=1
   else:
      y_pred_xgb[i]=0

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred_xgb)
cm

plot_confusion_matrix(conf_mat=cm, figsize=(4,4), show_normed= False)
plt.tight_layout()

metrics.accuracy_score(y_pred_xgb,y_test)

roc_auc_score(y_pred_xgb, y_test)

"""## LightGBM 3"""

import xgboost as xgb

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG3.csv'
TrainG3 = pd.read_csv(csv_path, sep=',')

TrainG3.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG3.drop(["a"], axis=1, inplace=True)

TrainG3.Respiracion = TrainG3.Respiracion.replace(["No valido"], -1)
TrainG3.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG3["SepsisLabel"])
X = (TrainG3.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

dtrain = xgb.DMatrix(X_train, label=y_train)

params = { 'learning_rate': .5,
           'objective':'binary:logistic',
           'eval_metric':'auc',
           'num_leaves':100,
           'max_depth':10}

xg=xgb.train(params, dtrain, 50)

dtest = xgb.DMatrix(X_test)
y_pred_xgb= xg.predict(dtest)

for i in range (0, X_test.shape[0]):
   if y_pred_xgb[i]>=.5:
      y_pred_xgb[i]=1
   else:
      y_pred_xgb[i]=0

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred_xgb)
cm

plot_confusion_matrix(conf_mat=cm, figsize=(4,4), show_normed= False)
plt.tight_layout()

metrics.accuracy_score(y_pred_xgb,y_test)

roc_auc_score(y_pred_xgb, y_test)

"""## Light GBM 4"""

import xgboost as xgb

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG4.csv'
TrainG4 = pd.read_csv(csv_path, sep=',')

TrainG4.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG4.drop(["a"], axis=1, inplace=True)

TrainG4.Respiracion = TrainG4.Respiracion.replace(["No valido"], -1)
TrainG4.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)
y = (TrainG4["SepsisLabel"])
X = (TrainG4.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

dtrain = xgb.DMatrix(X_train, label=y_train)

params = { 'learning_rate': .5,
           'objective':'binary:logistic',
           'eval_metric':'auc',
           'num_leaves':100,
           'max_depth':10}

xg=xgb.train(params, dtrain, 50)

dtest = xgb.DMatrix(X_test)
y_pred_xgb= xg.predict(dtest)

for i in range (0, X_test.shape[0]):
   if y_pred_xgb[i]>=.5:
      y_pred_xgb[i]=1
   else:
      y_pred_xgb[i]=0

#Matriz de Confusión
cm= confusion_matrix(y_test, y_pred_xgb)
cm

plot_confusion_matrix(conf_mat=cm, figsize=(4,4), show_normed= False)
plt.tight_layout()

metrics.accuracy_score(y_pred_xgb,y_test)

roc_auc_score(y_pred_xgb, y_test)

"""# Pruebas"""

import pandas as pd
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn import metrics
from sklearn.metrics import accuracy_score,roc_auc_score
from xgboost.sklearn import XGBClassifier

"""## G1"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG1.csv'
TrainG1 = pd.read_csv(csv_path, sep=',')

TrainG1.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG1.drop(["a"], axis=1, inplace=True)

TrainG1.Respiracion = TrainG1.Respiracion.replace(["No valido"], -1)
TrainG1.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)

y = (TrainG1["SepsisLabel"])
X = (TrainG1.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

"""### GBDT"""

Gbdt1=GradientBoostingClassifier(n_estimators = 19, random_state = 2016,min_samples_leaf = 8,) #CBDT
#Gbdt1.fit(X_train,y_train)

# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)

# define search space
space = dict()
space['max_features'] = ['auto', 'sqrt', 'log2']
space['max_depth'] = [None, 1, 3, 5, 10, 20]
space['subsample'] = [0.5, 1]
space['learning_rate'] = [0.001, 0.01, 0.1]

# define search
search = GridSearchCV(Gbdt1, space, scoring='accuracy', n_jobs=-1, cv=cv)

# execute search
result = search.fit(X_train, y_train)

# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

y_test_hot1 = label_binarize (y_test, classes = (0, 1)) # Convierta los datos de la etiqueta del conjunto de prueba en una matriz mediante codificación binaria
Gbdt_y_score1 = Gbdt1.decision_function (X_test) # Obtenga el valor de pérdida previsto de Gbdt
Gbdt_fpr1, Gbdt_tpr1, Gbdt_threasholds1 = metrics.roc_curve (y_test_hot1.ravel (), Gbdt_y_score1.ravel ()) # Calcular el valor ROC, Gbdt_threasholds es el umbral

# Se realiza la predicción
y_predGbdt1 = Gbdt1.predict(X_test)
y_predGbdt1

Gbdt_score1 = Gbdt1.score (X_train, y_train) # Tasa de precisión
print('Gbdt_score:',Gbdt_score1)

Gbdt_f11 = f1_score(y_test, y_predGbdt1)
print(Gbdt_f11)

Gbdt_auc1 = metrics.auc (Gbdt_fpr1, Gbdt_tpr1) #Gbdt_auc value
print('Gbdt_auc:',Gbdt_auc1)

#Matriz de Confusión
cm1= confusion_matrix(y_test, y_predGbdt1)
cm1

plot_confusion_matrix(conf_mat=cm1, figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

#Curva AUC

plt.plot(Gbdt_fpr1,Gbdt_tpr1)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC GBDT")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(Gbdt1, 'ModeloG1_GBDT.pkl')

"""### XGBC"""

Xgbc1=XGBClassifier(random_state=2018)  #Xgbc
Xgbc1.fit(X_train,y_train)
y_xgbc_pred1=Xgbc1.predict(X_test)

Xgbc_score1 = precision_score (y_test, y_xgbc_pred1) # Tasa de precisión
print('Xgbc_score:',Xgbc_score1)

Xgbc_f11 = f1_score(y_test, y_xgbc_pred1)
print(Xgbc_f11)

Xgbc_auc1 = roc_auc_score (y_test, y_xgbc_pred1) #Xgbc_auc value
print('Xgbc_auc:',Xgbc_auc1)

#Matriz de Confusión
cmxgbc1= confusion_matrix(y_test, y_xgbc_pred1)
cmxgbc1

plot_confusion_matrix(conf_mat=cmxgbc1, figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

y_test_probXgbc1 = Xgbc1.predict_proba(X_test)
fprXgbc1, tprXgbc1, thrsXgbc1 = roc_curve(y_test, y_test_probXgbc1[:,1])

#Curva AUC

plt.plot(fprXgbc1,tprXgbc1)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC XGBC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(Xgbc1, 'ModeloG1_XGBC.pkl')

"""### LGBMC"""

gbm1=lgb.LGBMClassifier(random_state=2018)  #lgb
gbm1.fit(X_train,y_train)
y_gbm_pred1=gbm1.predict(X_test)

gbm_score1 = precision_score (y_test, y_gbm_pred1) # Tasa de precisión
print('gbm_score:',gbm_score1)

gbm_auc1 = roc_auc_score (y_test, y_gbm_pred1) #gbm_auc value
print('gbm_auc:',gbm_auc1)

gbm_f11 = f1_score(y_test, y_gbm_pred1)
print(gbm_f11)

#Matriz de Confusión
cmgbm1= confusion_matrix(y_test, y_gbm_pred1)
cmgbm1

plot_confusion_matrix(conf_mat=cmgbm1,figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

y_test_probgbm1 = Xgbc1.predict_proba(X_test)
fprgbm1, tprgbm1, thrsgbm1 = roc_curve(y_test, y_test_probgbm1[:,1])

#Curva AUC

plt.plot(fprgbm1,tprgbm1)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC LGBMC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(gbm1, 'ModeloG1_LGBMC.pkl')

"""### Resultado en una grafica

"""

#Curva AUC

fig = plt.figure(figsize=(10,10))
fig.tight_layout()

plt.plot(fprgbm1,tprgbm1, label='GBM', color= 'green')
plt.plot(fprXgbc1,tprXgbc1,label='XGBC', color= 'orange')
plt.plot(Gbdt_fpr1,Gbdt_tpr1, label='GBDT', color= 'blue')
plt.plot([0,1], [0,1], "r--")

plt.title("ROC Resultados")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.legend()
plt.show()



"""## G2"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG2.csv'
TrainG2 = pd.read_csv(csv_path, sep=',')

TrainG2.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG2.drop(["a"], axis=1, inplace=True)

TrainG2.Respiracion = TrainG2.Respiracion.replace(["No valido"], -1)
TrainG2.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)

y = (TrainG2["SepsisLabel"])
X = (TrainG2.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

"""### GBDT"""

Gbdt2=GradientBoostingClassifier(random_state=2018) #CBDT
Gbdt2.fit(X_train,y_train)

y_test_hot2 = label_binarize (y_test, classes = (0, 1)) # Convierta los datos de la etiqueta del conjunto de prueba en una matriz mediante codificación binaria
Gbdt_y_score2 = Gbdt2.decision_function (X_test) # Obtenga el valor de pérdida previsto de Gbdt
Gbdt_fpr2, Gbdt_tpr2, Gbdt_threasholds2 = metrics.roc_curve (y_test_hot2.ravel (), Gbdt_y_score2.ravel ()) # Calcular el valor ROC, Gbdt_threasholds es el umbral

# Se realiza la predicción
y_predGbdt2 = Gbdt2.predict(X_test)
y_predGbdt2

Gbdt_score2 = Gbdt2.score (X_train, y_train) # Tasa de precisión
print('Gbdt_score:',Gbdt_score2)

Gbdt_f12 = f1_score(y_test, y_predGbdt2)
print(Gbdt_f12)

Gbdt_auc2 = metrics.auc (Gbdt_fpr2, Gbdt_tpr2) #Gbdt_auc value
print('Gbdt_auc:',Gbdt_auc2)

#Matriz de Confusión
cm2= confusion_matrix(y_test, y_predGbdt2)
cm2

plot_confusion_matrix(conf_mat=cm2,figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

#Curva AUC

plt.plot(Gbdt_fpr2,Gbdt_tpr2)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC GBDT")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(Gbdt2, 'ModeloG2_GBDT.pkl')

"""### XGBC"""

Xgbc2=XGBClassifier(random_state=2018)  #Xgbc
Xgbc2.fit(X_train,y_train)
y_xgbc_pred2=Xgbc2.predict(X_test)

Xgbc_score2 = precision_score (y_test, y_xgbc_pred2) # Tasa de precisión
print('Xgbc_score:',Xgbc_score2)

Xgbc_f12 = f1_score(y_test, y_xgbc_pred2)
print(Xgbc_f12)

Xgbc_auc2 = roc_auc_score (y_test, y_xgbc_pred2) #Xgbc_auc value
print('Xgbc_auc:',Xgbc_auc2)

#Matriz de Confusión
cmxgbc2= confusion_matrix(y_test, y_xgbc_pred2)
cmxgbc2

plot_confusion_matrix(conf_mat=cmxgbc2, figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

y_test_probXgbc2 = Xgbc2.predict_proba(X_test)
fprXgbc2, tprXgbc2, thrsXgbc2 = roc_curve(y_test, y_test_probXgbc2[:,1])

#Curva AUC

plt.plot(fprXgbc2,tprXgbc2)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC XGBC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(Xgbc2, 'ModeloG2_XGBC.pkl')

"""### LGBMC"""

gbm2=lgb.LGBMClassifier(random_state=2018)  #lgb
gbm2.fit(X_train,y_train)
y_gbm_pred2=gbm2.predict(X_test)

gbm_score2 = precision_score (y_test, y_gbm_pred2) # Tasa de precisión
print('gbm_score:',gbm_score2)

gbm_auc2 = roc_auc_score (y_test, y_gbm_pred2) #gbm_auc value
print('gbm_auc:',gbm_auc2)

gbm_f12 = f1_score(y_test, y_gbm_pred2)
print(gbm_f12)

#Matriz de Confusión
cmgbm2= confusion_matrix(y_test, y_gbm_pred2)
cmgbm2

plot_confusion_matrix(conf_mat=cmgbm2,figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

y_test_probgbm2 = Xgbc2.predict_proba(X_test)
fprgbm2, tprgbm2, thrsgbm2 = roc_curve(y_test, y_test_probgbm2[:,1])

#Curva AUC

plt.plot(fprgbm2,tprgbm2)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC LGBMC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(gbm2, 'ModeloG2_LGBMC.pkl')

"""### Resultado en una grafica

"""

#Curva AUC

fig = plt.figure(figsize=(10,10))
fig.tight_layout()

plt.plot(fprgbm2,tprgbm2, label='GBM', color= 'green')
plt.plot(fprXgbc2,tprXgbc2,label='XGBC', color= 'orange')
plt.plot(Gbdt_fpr2,Gbdt_tpr2, label='GBDT', color= 'blue')
plt.plot([0,1], [0,1], "r--")

plt.title("ROC Resultados")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.legend()
plt.show()



"""## G3"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG3.csv'
TrainG3 = pd.read_csv(csv_path, sep=',')

TrainG3.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG3.drop(["a"], axis=1, inplace=True)

TrainG3.Respiracion = TrainG3.Respiracion.replace(["No valido"], -1)
TrainG3.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)

y = (TrainG3["SepsisLabel"])
X = (TrainG3.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

"""### GBDT"""

Gbdt3=GradientBoostingClassifier(random_state=2018) #CBDT
Gbdt3.fit(X_train,y_train)

y_test_hot3 = label_binarize (y_test, classes = (0, 1)) # Convierta los datos de la etiqueta del conjunto de prueba en una matriz mediante codificación binaria
Gbdt_y_score3 = Gbdt3.decision_function (X_test) # Obtenga el valor de pérdida previsto de Gbdt
Gbdt_fpr3, Gbdt_tpr3, Gbdt_threasholds3 = metrics.roc_curve (y_test_hot3.ravel (), Gbdt_y_score3.ravel ()) # Calcular el valor ROC, Gbdt_threasholds es el umbral

# Se realiza la predicción
y_predGbdt3 = Gbdt3.predict(X_test)
y_predGbdt3

Gbdt_score3 = Gbdt3.score (X_train, y_train) # Tasa de precisión
print('Gbdt_score:',Gbdt_score3)

Gbdt_f13 = f1_score(y_test, y_predGbdt3)
print(Gbdt_f13)

Gbdt_auc3 = metrics.auc (Gbdt_fpr3, Gbdt_tpr3) #Gbdt_auc value
print('Gbdt_auc:',Gbdt_auc3)

#Matriz de Confusión
cm3= confusion_matrix(y_test, y_predGbdt3)
cm3

plot_confusion_matrix(conf_mat=cm3,figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

#Curva AUC

plt.plot(Gbdt_fpr3,Gbdt_tpr3)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC GBDT")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(Gbdt3, 'ModeloG3_GBDT.pkl')

"""### XGBC"""

Xgbc3=XGBClassifier(random_state=2018)  #Xgbc
Xgbc3.fit(X_train,y_train)
y_xgbc_pred3=Xgbc3.predict(X_test)

Xgbc_score3 = precision_score (y_test, y_xgbc_pred3) # Tasa de precisión
print('Xgbc_score:',Xgbc_score3)

Xgbc_f13 = f1_score(y_test, y_xgbc_pred3)
print(Xgbc_f13)

Xgbc_auc3 = roc_auc_score (y_test, y_xgbc_pred3) #Xgbc_auc value
print('Xgbc_auc:',Xgbc_auc3)

#Matriz de Confusión
cmxgbc3= confusion_matrix(y_test, y_xgbc_pred3)
cmxgbc3

plot_confusion_matrix(conf_mat=cmxgbc3, figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

y_test_probXgbc3 = Xgbc3.predict_proba(X_test)
fprXgbc3, tprXgbc3, thrsXgbc3 = roc_curve(y_test, y_test_probXgbc3[:,1])

#Curva AUC

plt.plot(fprXgbc3,tprXgbc3)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC XGBC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(Xgbc3, 'ModeloG3_XGBC.pkl')

"""### LGBMC"""

gbm3=lgb.LGBMClassifier(random_state=2018)  #lgb
gbm3.fit(X_train,y_train)
y_gbm_pred3=gbm3.predict(X_test)

gbm_score3 = precision_score (y_test, y_gbm_pred3) # Tasa de precisión
print('gbm_score:',gbm_score3)

gbm_auc3 = roc_auc_score (y_test, y_gbm_pred3) #gbm_auc value
print('gbm_auc:',gbm_auc3)

gbm_f13 = f1_score(y_test, y_gbm_pred3)
print(gbm_f13)

#Matriz de Confusión
cmgbm3= confusion_matrix(y_test, y_gbm_pred3)
cmgbm3

plot_confusion_matrix(conf_mat=cmgbm3, figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

y_test_probgbm3 = Xgbc3.predict_proba(X_test)
fprgbm3, tprgbm3, thrsgbm3 = roc_curve(y_test, y_test_probgbm3[:,1])

#Curva AUC

plt.plot(fprgbm3,tprgbm3)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC LGBMC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(gbm3, 'ModeloG3_LGBMC.pkl')

"""### Resultado en una grafica

"""

#Curva AUC

fig = plt.figure(figsize=(10,10))
fig.tight_layout()

plt.plot(fprgbm3,tprgbm3, label='GBM', color= 'green')
plt.plot(fprXgbc3,tprXgbc3,label='XGBC', color= 'orange')
plt.plot(Gbdt_fpr3,Gbdt_tpr3, label='GBDT', color= 'blue')
plt.plot([0,1], [0,1], "r--")

plt.title("ROC Resultados")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.legend()
plt.show()



"""## G4"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainG4.csv'
TrainG4 = pd.read_csv(csv_path, sep=',')

TrainG4.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainG4.drop(["a"], axis=1, inplace=True)

TrainG4.Respiracion = TrainG4.Respiracion.replace(["No valido"], -1)
TrainG4.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)

y = (TrainG4["SepsisLabel"])
X = (TrainG4.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

"""### GBDT"""

Gbdt4 = GradientBoostingClassifier(random_state=2018) #CBDT
Gbdt4.fit(X_train,y_train)

y_test_hot4 = label_binarize (y_test, classes = (0, 1)) # Convierta los datos de la etiqueta del conjunto de prueba en una matriz mediante codificación binaria
Gbdt_y_score4 = Gbdt4.decision_function (X_test) # Obtenga el valor de pérdida previsto de Gbdt
Gbdt_fpr4, Gbdt_tpr4, Gbdt_threasholds4 = metrics.roc_curve (y_test_hot4.ravel (), Gbdt_y_score4.ravel ()) # Calcular el valor ROC, Gbdt_threasholds es el umbral

# Se realiza la predicción
y_predGbdt4 = Gbdt4.predict(X_test)
y_predGbdt4

Gbdt_score4 = Gbdt4.score (X_train, y_train) # Tasa de precisión
print('Gbdt_score:',Gbdt_score4)

Gbdt_f14 = f1_score(y_test, y_predGbdt4)
print(Gbdt_f14)

Gbdt_auc4 = metrics.auc (Gbdt_fpr4, Gbdt_tpr4) #Gbdt_auc value
print('Gbdt_auc:',Gbdt_auc4)

#Matriz de Confusión
cm4= confusion_matrix(y_test, y_predGbdt4)
cm4

plot_confusion_matrix(conf_mat=cm4, figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

#Curva AUC

plt.plot(Gbdt_fpr4,Gbdt_tpr4)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC GBDT")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(Gbdt4, 'ModeloG4_GBDT.pkl')

"""### XGBC"""

Xgbc4 = XGBClassifier(random_state=2018)  #Xgbc
Xgbc4.fit(X_train,y_train)
y_xgbc_pred4 = Xgbc4.predict(X_test)

Xgbc_score4 = precision_score (y_test, y_xgbc_pred4) # Tasa de precisión
print('Xgbc_score:',Xgbc_score4)

Xgbc_f14 = f1_score(y_test, y_xgbc_pred4)
print(Xgbc_f14)

Xgbc_auc4 = roc_auc_score (y_test, y_xgbc_pred4) #Xgbc_auc value
print('Xgbc_auc:',Xgbc_auc4)

#Matriz de Confusión
cmxgbc4= confusion_matrix(y_test, y_xgbc_pred4)
cmxgbc4

plot_confusion_matrix(conf_mat=cmxgbc4, figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

y_test_probXgbc4 = Xgbc4.predict_proba(X_test)
fprXgbc4, tprXgbc4, thrsXgbc4 = roc_curve(y_test, y_test_probXgbc4[:,1])

#Curva AUC

plt.plot(fprXgbc4,tprXgbc4)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC XGBC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(Xgbc4, 'ModeloG4_XGBC.pkl')

"""### LGBMC"""

gbm4 = lgb.LGBMClassifier(random_state=2018)  #lgb
gbm4.fit(X_train,y_train)
y_gbm_pred4=gbm4.predict(X_test)

gbm_score4 = precision_score (y_test, y_gbm_pred4) # Tasa de precisión
print('gbm_score:',gbm_score4)

gbm_auc4 = roc_auc_score (y_test, y_gbm_pred4) #gbm_auc value
print('gbm_auc:',gbm_auc4)

gbm_f14 = f1_score(y_test, y_gbm_pred4)
print(gbm_f14)

#Matriz de Confusión
cmgbm4= confusion_matrix(y_test, y_gbm_pred4)
cmgbm4

plot_confusion_matrix(conf_mat=cmgbm4,figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

y_test_probgbm4 = Xgbc4.predict_proba(X_test)
fprgbm4, tprgbm4, thrsgbm4 = roc_curve(y_test, y_test_probgbm4[:,1])

#Curva AUC

plt.plot(fprgbm4,tprgbm4)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC LGBMC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(gbm4, 'ModeloG4_LGBMC.pkl')

"""### Resultado en una grafica

"""

#Curva AUC

fig = plt.figure(figsize=(10,10))
fig.tight_layout()

plt.plot(fprgbm4,tprgbm4, label='GBM', color= 'green')
plt.plot(fprXgbc4,tprXgbc4,label='XGBC', color= 'orange')
plt.plot(Gbdt_fpr4,Gbdt_tpr4, label='GBDT', color= 'blue')
plt.plot([0,1], [0,1], "r--")

plt.title("ROC Resultados")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.legend()
plt.show()



"""## GRUPO COMPLETO"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/TrainCompleto.csv'
TrainCompleto = pd.read_csv(csv_path, sep=',')

TrainCompleto.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainCompleto.drop(["a"], axis=1, inplace=True)

TrainCompleto.Respiracion = TrainCompleto.Respiracion.replace(["No valido"], -1)
TrainCompleto.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)

y = (TrainCompleto["SepsisLabel"])
X = (TrainCompleto.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

#División del dataset con split entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4, stratify=y)

print(u'Dimensiones en train \n-X:{}\-Y{}'.format(X_train.shape, y_train.shape))
print(u'Dimensiones en test \n-X:{}\-Y{}'.format(X_test.shape, y_test.shape))

"""### GBDT"""

Gbdt1=GradientBoostingClassifier(n_estimators = 19, random_state = 2016,min_samples_leaf = 8,) #CBDT
#Gbdt1.fit(X_train,y_train)

# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)

# define search space
space = dict()
space['max_features'] = ['auto', 'sqrt', 'log2']
space['max_depth'] = [None, 1, 3, 5, 10, 20]
space['subsample'] = [0.5, 1]
space['learning_rate'] = [0.001, 0.01, 0.1]

# define search
search = GridSearchCV(Gbdt1, space, scoring='accuracy', n_jobs=-1, cv=cv)

# execute search
result = search.fit(X_train, y_train)

# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

y_test_hot1 = label_binarize (y_test, classes = (0, 1)) # Convierta los datos de la etiqueta del conjunto de prueba en una matriz mediante codificación binaria
Gbdt_y_score1 = search.decision_function (X_test) # Obtenga el valor de pérdida previsto de Gbdt
Gbdt_fpr1, Gbdt_tpr1, Gbdt_threasholds1 = metrics.roc_curve (y_test_hot1.ravel (), Gbdt_y_score1.ravel ()) # Calcular el valor ROC, Gbdt_threasholds es el umbral

# Se realiza la predicción
y_predGbdt1 = search.predict(X_test)
y_predGbdt1

Gbdt_score1 = search.score (X_train, y_train) # Tasa de precisión
print('Gbdt_score:',Gbdt_score1)

Gbdt_f11 = f1_score(y_test, y_predGbdt1)
print(Gbdt_f11)

Gbdt_auc1 = metrics.auc (Gbdt_fpr1, Gbdt_tpr1) #Gbdt_auc value
print('Gbdt_auc:',Gbdt_auc1)

#Matriz de Confusión
cm1= confusion_matrix(y_test, y_predGbdt1)
cm1

plot_confusion_matrix(conf_mat=cm1, figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

#Curva AUC

plt.plot(Gbdt_fpr1,Gbdt_tpr1)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC GBDT")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(Gbdt1, 'ModeloG1_GBDT.pkl')

"""### XGBC"""

Xgbc1=XGBClassifier(random_state=2018)  #Xgbc
Xgbc1.fit(X_train,y_train)
y_xgbc_pred1=Xgbc1.predict(X_test)

Xgbc_score1 = precision_score (y_test, y_xgbc_pred1) # Tasa de precisión
print('Xgbc_score:',Xgbc_score1)

Xgbc_f11 = f1_score(y_test, y_xgbc_pred1)
print(Xgbc_f11)

Xgbc_auc1 = roc_auc_score (y_test, y_xgbc_pred1) #Xgbc_auc value
print('Xgbc_auc:',Xgbc_auc1)

#Matriz de Confusión
cmxgbc1= confusion_matrix(y_test, y_xgbc_pred1)
cmxgbc1

plot_confusion_matrix(conf_mat=cmxgbc1, figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

y_test_probXgbc1 = Xgbc1.predict_proba(X_test)
fprXgbc1, tprXgbc1, thrsXgbc1 = roc_curve(y_test, y_test_probXgbc1[:,1])

#Curva AUC

plt.plot(fprXgbc1,tprXgbc1)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC XGBC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(Xgbc1, 'ModeloG1_XGBC.pkl')

"""### LGBMC"""

gbm1=lgb.LGBMClassifier(random_state=2018)  #lgb
#gbm1.fit(X_train,y_train)

# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)

# define search space
space = dict()
space['n_estimators'] = [100, 500, 1000]
space['max_depth'] = [-1, 1, 3, 5, 10, 20]
space['subsample'] = [0.5, 1]
space['learning_rate'] = [0.001, 0.01, 0.1]
space['boosting_type'] = ['gbdt']

# define search
search = GridSearchCV(gbm1, space, scoring='accuracy', n_jobs=-1, cv=cv)

# execute search
result = search.fit(X_train, y_train)

# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

y_gbm_pred1=search.predict(X_test)

gbm_score1 = precision_score (y_test, y_gbm_pred1) # Tasa de precisión
print('gbm_score:',gbm_score1)

gbm_auc1 = roc_auc_score (y_test, y_gbm_pred1) #gbm_auc value
print('gbm_auc:',gbm_auc1)

gbm_f11 = f1_score(y_test, y_gbm_pred1)
print(gbm_f11)

#Matriz de Confusión
cmgbm1= confusion_matrix(y_test, y_gbm_pred1)
cmgbm1

plot_confusion_matrix(conf_mat=cmgbm1,figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

y_test_probgbm1 = Xgbc1.predict_proba(X_test)
fprgbm1, tprgbm1, thrsgbm1 = roc_curve(y_test, y_test_probgbm1[:,1])

#Curva AUC

plt.plot(fprgbm1,tprgbm1)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC LGBMC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(gbm1, 'ModeloG1_LGBMC.pkl')

"""### Resultado en una grafica

"""

#Curva AUC

fig = plt.figure(figsize=(10,10))
fig.tight_layout()

plt.plot(fprgbm1,tprgbm1, label='GBM', color= 'green')
plt.plot(fprXgbc1,tprXgbc1,label='XGBC', color= 'orange')
plt.plot(Gbdt_fpr1,Gbdt_tpr1, label='GBDT', color= 'blue')
plt.plot([0,1], [0,1], "r--")

plt.title("ROC Resultados")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.legend()
plt.show()



"""## GRUPO COMPLETO Train y Test"""

# Se carga la data seleccionada para el estudio

csv_path = '/content/TrainCompleto.csv'
TrainCompleto = pd.read_csv(csv_path, sep=',')

csv_path = '/content/TestCompleto.csv'
TestCompleto = pd.read_csv(csv_path, sep=',')


TrainCompleto.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TrainCompleto.drop(["a"], axis=1, inplace=True)

TrainCompleto.Respiracion = TrainCompleto.Respiracion.replace(["No valido"], -1)
TrainCompleto.astype({'Respiracion':'float64'}).dtypes

TestCompleto.rename({"Unnamed: 0":"a"}, axis="columns", inplace=True)
TestCompleto.drop(["a"], axis=1, inplace=True)

TestCompleto.Respiracion = TestCompleto.Respiracion.replace(["No valido"], -1)
TestCompleto.astype({'Respiracion':'float64'}).dtypes

# Se escogen la variables en X que se van a verificar para el analisis, y en y para el atributo que queremos identificar (De la data de entrenamiento)

y = (TestCompleto["SepsisLabel"])
X = (TrainCompleto.drop(['SepsisLabel','Paciente','Respiracion'], axis=1))

"""### GBDT"""

Gbdt1=GradientBoostingClassifier(random_state=2018) #CBDT
Gbdt1.fit(X,y)

y_test_hot1 = label_binarize (y_test, classes = (0, 1)) # Convierta los datos de la etiqueta del conjunto de prueba en una matriz mediante codificación binaria
Gbdt_y_score1 = Gbdt1.decision_function (X_test) # Obtenga el valor de pérdida previsto de Gbdt
Gbdt_fpr1, Gbdt_tpr1, Gbdt_threasholds1 = metrics.roc_curve (y_test_hot1.ravel (), Gbdt_y_score1.ravel ()) # Calcular el valor ROC, Gbdt_threasholds es el umbral

# Se realiza la predicción
y_predGbdt1 = Gbdt1.predict(X_test)
y_predGbdt1

Gbdt_score1 = Gbdt1.score (X_train, y_train) # Tasa de precisión
print('Gbdt_score:',Gbdt_score1)

Gbdt_f11 = f1_score(y_test, y_predGbdt1)
print(Gbdt_f11)

Gbdt_auc1 = metrics.auc (Gbdt_fpr1, Gbdt_tpr1) #Gbdt_auc value
print('Gbdt_auc:',Gbdt_auc1)

#Matriz de Confusión
cm1= confusion_matrix(y_test, y_predGbdt1)
cm1

plot_confusion_matrix(conf_mat=cm1, figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

#Curva AUC

plt.plot(Gbdt_fpr1,Gbdt_tpr1)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC GBDT")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(Gbdt1, 'ModeloG1_GBDT.pkl')

"""### XGBC"""

Xgbc1=XGBClassifier(random_state=2018)  #Xgbc
Xgbc1.fit(X_train,y_train)
y_xgbc_pred1=Xgbc1.predict(X_test)

Xgbc_score1 = precision_score (y_test, y_xgbc_pred1) # Tasa de precisión
print('Xgbc_score:',Xgbc_score1)

Xgbc_f11 = f1_score(y_test, y_xgbc_pred1)
print(Xgbc_f11)

Xgbc_auc1 = roc_auc_score (y_test, y_xgbc_pred1) #Xgbc_auc value
print('Xgbc_auc:',Xgbc_auc1)

#Matriz de Confusión
cmxgbc1= confusion_matrix(y_test, y_xgbc_pred1)
cmxgbc1

plot_confusion_matrix(conf_mat=cmxgbc1, figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

y_test_probXgbc1 = Xgbc1.predict_proba(X_test)
fprXgbc1, tprXgbc1, thrsXgbc1 = roc_curve(y_test, y_test_probXgbc1[:,1])

#Curva AUC

plt.plot(fprXgbc1,tprXgbc1)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC XGBC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(Xgbc1, 'ModeloG1_XGBC.pkl')

"""### LGBMC"""

gbm1=lgb.LGBMClassifier(random_state=2018)  #lgb
gbm1.fit(X_train,y_train)
y_gbm_pred1=gbm1.predict(X_test)

gbm_score1 = precision_score (y_test, y_gbm_pred1) # Tasa de precisión
print('gbm_score:',gbm_score1)

gbm_auc1 = roc_auc_score (y_test, y_gbm_pred1) #gbm_auc value
print('gbm_auc:',gbm_auc1)

gbm_f11 = f1_score(y_test, y_gbm_pred1)
print(gbm_f11)

#Matriz de Confusión
cmgbm1= confusion_matrix(y_test, y_gbm_pred1)
cmgbm1

plot_confusion_matrix(conf_mat=cmgbm1,figsize=(5,5), show_normed= False, cmap='Set2')
plt.tight_layout()

y_test_probgbm1 = Xgbc1.predict_proba(X_test)
fprgbm1, tprgbm1, thrsgbm1 = roc_curve(y_test, y_test_probgbm1[:,1])

#Curva AUC

plt.plot(fprgbm1,tprgbm1)
plt.plot([0,1], [0,1], "r--")
plt.title("ROC LGBMC")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.show()

joblib.dump(gbm1, 'ModeloG1_LGBMC.pkl')

"""### Resultado en una grafica

"""

#Curva AUC

fig = plt.figure(figsize=(10,10))
fig.tight_layout()

plt.plot(fprgbm1,tprgbm1, label='GBM', color= 'green')
plt.plot(fprXgbc1,tprXgbc1,label='XGBC', color= 'orange')
plt.plot(Gbdt_fpr1,Gbdt_tpr1, label='GBDT', color= 'blue')
plt.plot([0,1], [0,1], "r--")

plt.title("ROC Resultados")
plt.xlabel("Falsos Positivos")
plt.ylabel ("Verdaderos Psotivos")
plt.legend()
plt.show()



"""# Tabla de resultados"""

# Se carga la data seleccionada para el estudio
csv_path = '/content/ResultadosModelos (1).csv'
Resultado1 = pd.read_csv(csv_path, sep=',')

for i in range(0,len(Resultado1)):
  
  if(i == 0):
    RFscore1 = Resultado1.loc[i, 'RF_Score']
    RFpuntaje1 = Resultado1.loc[i, 'RF_F1']
    RFauc1 = Resultado1.loc[i, 'RF_AUC']

  if(i == 1):
    RFscore2 = Resultado1.loc[i, 'RF_Score']
    RFpuntaje2 = Resultado1.loc[i, 'RF_F1']
    RFauc2 = Resultado1.loc[i, 'RF_AUC']

  if(i == 2):
    RFscore3 = Resultado1.loc[i, 'RF_Score']
    RFpuntaje3 = Resultado1.loc[i, 'RF_F1']
    RFauc3 = Resultado1.loc[i, 'RF_AUC']

  if(i == 3):
    RFscore4 = Resultado1.loc[i, 'RF_Score']
    RFpuntaje4 = Resultado1.loc[i, 'RF_F1']
    RFauc4 = Resultado1.loc[i, 'RF_AUC']

datos = {'RF_Score': [ RFscore1, RFscore2, RFscore3, RFscore4],
         'GBDT_Score': [ Gbdt_score1, Gbdt_score2, Gbdt_score3, Gbdt_score4],
         'XGBC_Score': [ Xgbc_score1, Xgbc_score2, Xgbc_score3, Xgbc_score4],
         'LGBMC_Score': [ gbm_score1, gbm_score2, gbm_score3, gbm_score4],
         'RF_F1': [ RFpuntaje1, RFpuntaje2, RFpuntaje3, RFpuntaje4],
         'GBDT_F1': [ Gbdt_f11, Gbdt_f12, Gbdt_f13, Gbdt_f14],
         'XGBC_F1': [ Xgbc_f11, Xgbc_f12, Xgbc_f13, Xgbc_f14],
         'LGBMC_F1': [ gbm_f11, gbm_f12, gbm_f13, gbm_f14],
         'RF_AUC': [ RFauc1, RFauc2, RFauc3, RFauc4],
         'GBDT_AUC': [ Gbdt_auc1, Gbdt_auc2, Gbdt_auc3, Gbdt_auc4],
         'XGBC_AUC': [ Xgbc_auc1, Xgbc_auc2, Xgbc_auc3, Xgbc_auc4],
         'LGBMC_AUC': [ gbm_auc1, gbm_auc2, gbm_auc3, gbm_auc4]}

ResultadosArboles = pd.DataFrame(datos, index=['M1', 'M2', 'M3' , 'M4'])
ResultadosArboles.to_csv('ResultadosModelosArboles.csv')
ResultadosArboles

csv_path = '/content/ResultadosModelosArboles.csv'
Resultado2 = pd.read_csv(csv_path, sep=',')

Resultado1

Resultado2



